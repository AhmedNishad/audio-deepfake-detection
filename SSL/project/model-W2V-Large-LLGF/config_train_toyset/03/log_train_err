D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
2024-03-13 16:30:00 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\torch\nn\utils\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.
  warnings.warn("torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.")
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\torch\nn\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
50,LA_T_3935691,0,39156,0, 1/118, Time: 0.410323s, Loss: 0.857081
13,LA_T_1724943,0,60906,0, 2/118, Time: 0.410323s, Loss: 0.857081
41,LA_T_3391018,0,57402,0, 3/118, Time: 0.410323s, Loss: 0.857081
7,LA_T_1518499,0,29284,0, 4/118, Time: 0.410323s, Loss: 0.857081
2,LA_T_1346935,0,45741,0, 5/118, Time: 0.410323s, Loss: 0.857081
35,LA_T_3176741,0,62198,0, 6/118, Time: 0.410323s, Loss: 0.857081
114,LA_T_9668514,0,54564,0, 7/118, Time: 0.410323s, Loss: 0.857081
103,LA_T_7866363,0,63473,0, 8/118, Time: 0.410323s, Loss: 0.857081
94,LA_T_7281115,1,11690,64000, 9/118, Time: 0.410323s, Loss: 0.857081
113,LA_T_9633872,0,27407,0, 10/118, Time: 0.410323s, Loss: 0.857081
116,LA_T_9746209,1,16967,64000, 11/118, Time: 0.410323s, Loss: 0.857081
18,LA_T_1909651,2,24481,128000, 12/118, Time: 0.410323s, Loss: 0.857081
10,LA_T_1630611,0,58109,0, 13/118, Time: 0.410323s, Loss: 0.857081
1,LA_T_1258641,0,44562,0, 14/118, Time: 0.410323s, Loss: 0.857081
29,LA_T_2422854,0,62661,0, 15/118, Time: 0.410323s, Loss: 0.857081
80,LA_T_6487227,0,44111,0, 16/118, Time: 0.410323s, Loss: 0.857081
15,LA_T_1870524,0,43190,0, 17/118, Time: 0.410323s, Loss: 0.857081
69,LA_T_5786445,0,64000,0, 18/118, Time: 0.410323s, Loss: 0.857081
39,LA_T_3250806,0,61271,0, 19/118, Time: 0.410323s, Loss: 0.857081
31,LA_T_2677562,0,63649,0, 20/118, Time: 0.410323s, Loss: 0.857081
102,LA_T_7808689,0,64000,0, 21/118, Time: 0.410323s, Loss: 0.857081
25,LA_T_2333843,0,61708,0, 22/118, Time: 0.410323s, Loss: 0.857081
101,LA_T_7706110,0,24083,0, 23/118, Time: 0.410323s, Loss: 0.857081
44,LA_T_3527643,0,64000,0, 24/118, Time: 0.410323s, Loss: 0.857081
14,LA_T_1836557,0,43646,0, 25/118, Time: 0.410323s, Loss: 0.857081
46,LA_T_3588714,0,46298,0, 26/118, Time: 0.410323s, Loss: 0.857081
61,LA_T_5209704,0,64000,0, 27/118, Time: 0.410323s, Loss: 0.857081
112,LA_T_9540683,0,25430,0, 28/118, Time: 0.410323s, Loss: 0.857081
85,LA_T_6941395,0,64000,0, 29/118, Time: 0.410323s, Loss: 0.857081
67,LA_T_5492534,0,28365,0, 30/118, Time: 0.410323s, Loss: 0.857081
95,LA_T_7314513,0,39437,0, 31/118, Time: 0.410323s, Loss: 0.857081
89,LA_T_7124444,0,64000,0, 32/118, Time: 0.410323s, Loss: 0.857081
84,LA_T_6822716,0,27313,0, 33/118, Time: 0.410323s, Loss: 0.857081
108,LA_T_8234484,0,46183,0, 34/118, Time: 0.410323s, Loss: 0.857081
70,LA_T_5883755,0,64000,0, 35/118, Time: 0.410323s, Loss: 0.857081
4,LA_T_1470918,0,39641,0, 36/118, Time: 0.410323s, Loss: 0.857081
88,LA_T_7020532,0,59863,0, 37/118, Time: 0.410323s, Loss: 0.857081
59,LA_T_5015679,0,41144,0, 38/118, Time: 0.410323s, Loss: 0.857081
52,LA_T_4096754,0,31273,0, 39/118, Time: 0.410323s, Loss: 0.857081
21,LA_T_2277153,0,64000,0, 40/118, Time: 0.410323s, Loss: 0.857081
45,LA_T_3527643,1,8295,64000, 41/118, Time: 0.410323s, Loss: 0.857081
86,LA_T_6941395,1,29307,64000, 42/118, Time: 0.410323s, Loss: 0.857081
11,LA_T_1653822,0,64000,0, 43/118, Time: 0.410323s, Loss: 0.857081
58,LA_T_4928920,0,64000,0, 44/118, Time: 0.410323s, Loss: 0.857081
117,LA_T_9830298,0,64000,0, 45/118, Time: 0.410323s, Loss: 0.857081
33,LA_T_3021659,0,64000,0, 46/118, Time: 0.410323s, Loss: 0.857081
92,LA_T_7273305,0,53173,0, 47/118, Time: 0.410323s, Loss: 0.857081
66,LA_T_5433188,0,34172,0, 48/118, Time: 0.410323s, Loss: 0.857081
96,LA_T_7359423,0,50164,0, 49/118, Time: 0.410323s, Loss: 0.857081
91,LA_T_7223887,0,40210,0, 50/118, Time: 0.410323s, Loss: 0.857081
79,LA_T_6476207,0,54948,0, 51/118, Time: 0.410323s, Loss: 0.857081
81,LA_T_6521388,0,64000,0, 52/118, Time: 0.410323s, Loss: 0.857081
68,LA_T_5522733,0,61381,0, 53/118, Time: 0.410323s, Loss: 0.857081
20,LA_T_2269038,0,63442,0, 54/118, Time: 0.410323s, Loss: 0.857081
110,LA_T_8681550,0,40836,0, 55/118, Time: 0.410323s, Loss: 0.857081
73,LA_T_5978739,0,33363,0, 56/118, Time: 0.410323s, Loss: 0.857081
78,LA_T_6435787,0,43614,0, 57/118, Time: 0.410323s, Loss: 0.857081
75,LA_T_6331069,0,64000,0, 58/118, Time: 0.410323s, Loss: 0.857081
56,LA_T_4725126,0,61141,0, 59/118, Time: 0.410323s, Loss: 0.857081
109,LA_T_8527420,0,63377,0, 60/118, Time: 0.410323s, Loss: 0.857081
106,LA_T_8090857,0,64000,0, 61/118, Time: 0.410323s, Loss: 0.857081
28,LA_T_2419035,1,10625,64000, 62/118, Time: 0.410323s, Loss: 0.857081
111,LA_T_9226984,0,45529,0, 63/118, Time: 0.410323s, Loss: 0.857081
87,LA_T_6960076,0,42296,0, 64/118, Time: 0.410323s, Loss: 0.857081
53,LA_T_4512109,0,51563,0, 65/118, Time: 0.510676s, Loss: 0.213408
54,LA_T_4584407,0,36921,0, 66/118, Time: 0.510676s, Loss: 0.213408
42,LA_T_3467377,0,64000,0, 67/118, Time: 0.510676s, Loss: 0.213408
100,LA_T_7550620,0,44981,0, 68/118, Time: 0.510676s, Loss: 0.213408
47,LA_T_3627265,0,64000,0, 69/118, Time: 0.510676s, Loss: 0.213408
83,LA_T_6751630,0,62290,0, 70/118, Time: 0.510676s, Loss: 0.213408
93,LA_T_7281115,0,64000,0, 71/118, Time: 0.510676s, Loss: 0.213408
5,LA_T_1486451,0,50406,0, 72/118, Time: 0.510676s, Loss: 0.213408
57,LA_T_4774044,0,59379,0, 73/118, Time: 0.510676s, Loss: 0.213408
99,LA_T_7529623,0,43309,0, 74/118, Time: 0.510676s, Loss: 0.213408
76,LA_T_6331069,1,64000,64000, 75/118, Time: 0.510676s, Loss: 0.213408
104,LA_T_7888797,0,26626,0, 76/118, Time: 0.510676s, Loss: 0.213408
64,LA_T_5258800,0,54370,0, 77/118, Time: 0.510676s, Loss: 0.213408
16,LA_T_1909651,0,64000,0, 78/118, Time: 0.510676s, Loss: 0.213408
74,LA_T_6301739,0,41843,0, 79/118, Time: 0.510676s, Loss: 0.213408
82,LA_T_6728875,0,64000,0, 80/118, Time: 0.510676s, Loss: 0.213408
63,LA_T_5214047,0,41920,0, 81/118, Time: 0.510676s, Loss: 0.213408
22,LA_T_2277153,1,21822,64000, 82/118, Time: 0.510676s, Loss: 0.213408
8,LA_T_1589546,0,64000,0, 83/118, Time: 0.510676s, Loss: 0.213408
27,LA_T_2419035,0,64000,0, 84/118, Time: 0.510676s, Loss: 0.213408
36,LA_T_3189628,0,64000,0, 85/118, Time: 0.510676s, Loss: 0.213408
105,LA_T_8007992,0,45465,0, 86/118, Time: 0.510676s, Loss: 0.213408
40,LA_T_3319380,0,42032,0, 87/118, Time: 0.510676s, Loss: 0.213408
43,LA_T_3467377,1,26131,64000, 88/118, Time: 0.510676s, Loss: 0.213408
49,LA_T_3758169,0,46047,0, 89/118, Time: 0.510676s, Loss: 0.213408
62,LA_T_5209704,1,34511,64000, 90/118, Time: 0.510676s, Loss: 0.213408
107,LA_T_8206162,0,55328,0, 91/118, Time: 0.510676s, Loss: 0.213408
98,LA_T_7422011,0,45646,0, 92/118, Time: 0.510676s, Loss: 0.213408
37,LA_T_3189628,1,15851,64000, 93/118, Time: 0.510676s, Loss: 0.213408
71,LA_T_5883755,1,19926,64000, 94/118, Time: 0.510676s, Loss: 0.213408
97,LA_T_7405543,0,36914,0, 95/118, Time: 0.510676s, Loss: 0.213408
65,LA_T_5360018,0,54554,0, 96/118, Time: 0.510676s, Loss: 0.213408
30,LA_T_2584761,0,47107,0, 97/118, Time: 0.510676s, Loss: 0.213408
55,LA_T_4630359,0,64000,0, 98/118, Time: 0.510676s, Loss: 0.213408
26,LA_T_2354581,0,47687,0, 99/118, Time: 0.510676s, Loss: 0.213408
19,LA_T_2052267,0,38415,0, 100/118, Time: 0.510676s, Loss: 0.213408
32,LA_T_2995069,0,49112,0, 101/118, Time: 0.510676s, Loss: 0.213408
0,LA_T_1154440,0,30107,0, 102/118, Time: 0.510676s, Loss: 0.213408
6,LA_T_1490244,0,55572,0, 103/118, Time: 0.510676s, Loss: 0.213408
115,LA_T_9746209,0,64000,0, 104/118, Time: 0.510676s, Loss: 0.213408
34,LA_T_3021659,1,10227,64000, 105/118, Time: 0.510676s, Loss: 0.213408
12,LA_T_1653822,1,9756,64000, 106/118, Time: 0.510676s, Loss: 0.213408
17,LA_T_1909651,1,64000,64000, 107/118, Time: 0.510676s, Loss: 0.213408
3,LA_T_1373588,0,46949,0, 108/118, Time: 0.510676s, Loss: 0.213408
23,LA_T_2320617,0,56846,0, 109/118, Time: 0.510676s, Loss: 0.213408
24,LA_T_2327393,0,60701,0, 110/118, Time: 0.510676s, Loss: 0.213408
77,LA_T_6390981,0,64000,0, 111/118, Time: 0.510676s, Loss: 0.213408
51,LA_T_3993688,0,48709,0, 112/118, Time: 0.510676s, Loss: 0.213408
9,LA_T_1589546,1,9736,64000, 113/118, Time: 0.510676s, Loss: 0.213408
72,LA_T_5894355,0,64000,0, 114/118, Time: 0.510676s, Loss: 0.213408
90,LA_T_7124444,1,21405,64000, 115/118, Time: 0.510676s, Loss: 0.213408
38,LA_T_3220265,0,38149,0, 116/118, Time: 0.510676s, Loss: 0.213408
60,LA_T_5205025,0,61550,0, 117/118, Time: 0.510676s, Loss: 0.213408
48,LA_T_3627265,1,44402,64000, 118/118, Time: 0.510676s, Loss: 0.213408
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
2,LA_D_1317561,0,64000,0, 1/63, Time: 0.269670s, Loss: 0.280513
42,LA_D_6502788,0,29166,0, 2/63, Time: 0.269670s, Loss: 0.280513
34,LA_D_5741681,0,44990,0, 3/63, Time: 0.269670s, Loss: 0.280513
6,LA_D_1580841,0,38838,0, 4/63, Time: 0.269670s, Loss: 0.280513
53,LA_D_8584336,0,61424,0, 5/63, Time: 0.269670s, Loss: 0.280513
18,LA_D_3983088,0,21649,0, 6/63, Time: 0.269670s, Loss: 0.280513
1,LA_D_1179848,1,29541,64000, 7/63, Time: 0.269670s, Loss: 0.280513
33,LA_D_5659407,0,64000,0, 8/63, Time: 0.269670s, Loss: 0.280513
29,LA_D_5300881,1,27489,64000, 9/63, Time: 0.269670s, Loss: 0.280513
4,LA_D_1366945,0,45986,0, 10/63, Time: 0.269670s, Loss: 0.280513
14,LA_D_2949136,1,27301,64000, 11/63, Time: 0.269670s, Loss: 0.280513
52,LA_D_8284460,0,50174,0, 12/63, Time: 0.269670s, Loss: 0.280513
54,LA_D_8998984,0,37498,0, 13/63, Time: 0.269670s, Loss: 0.280513
40,LA_D_6055606,0,53176,0, 14/63, Time: 0.269670s, Loss: 0.280513
9,LA_D_2082512,0,53318,0, 15/63, Time: 0.269670s, Loss: 0.280513
22,LA_D_4394367,0,61722,0, 16/63, Time: 0.269670s, Loss: 0.280513
38,LA_D_5944972,0,64000,0, 17/63, Time: 0.269670s, Loss: 0.280513
46,LA_D_7862876,0,57311,0, 18/63, Time: 0.269670s, Loss: 0.280513
10,LA_D_2648941,0,64000,0, 19/63, Time: 0.269670s, Loss: 0.280513
13,LA_D_2949136,0,64000,0, 20/63, Time: 0.269670s, Loss: 0.280513
23,LA_D_4519635,0,64000,0, 21/63, Time: 0.269670s, Loss: 0.280513
51,LA_D_8228250,0,42344,0, 22/63, Time: 0.269670s, Loss: 0.280513
47,LA_D_7869978,0,64000,0, 23/63, Time: 0.269670s, Loss: 0.280513
60,LA_D_9686838,1,28544,64000, 24/63, Time: 0.269670s, Loss: 0.280513
19,LA_D_4013191,0,34443,0, 25/63, Time: 0.269670s, Loss: 0.280513
61,LA_D_9753761,0,64000,0, 26/63, Time: 0.269670s, Loss: 0.280513
55,LA_D_9192205,0,40612,0, 27/63, Time: 0.269670s, Loss: 0.280513
49,LA_D_7933136,0,64000,0, 28/63, Time: 0.269670s, Loss: 0.280513
8,LA_D_1886178,0,40092,0, 29/63, Time: 0.269670s, Loss: 0.280513
43,LA_D_7026375,0,61915,0, 30/63, Time: 0.269670s, Loss: 0.280513
27,LA_D_5239066,1,30014,64000, 31/63, Time: 0.269670s, Loss: 0.280513
57,LA_D_9493396,0,40904,0, 32/63, Time: 0.269670s, Loss: 0.280513
15,LA_D_3203408,0,49607,0, 33/63, Time: 0.269670s, Loss: 0.280513
12,LA_D_2896709,0,64000,0, 34/63, Time: 0.269670s, Loss: 0.280513
59,LA_D_9686838,0,64000,0, 35/63, Time: 0.269670s, Loss: 0.280513
28,LA_D_5300881,0,64000,0, 36/63, Time: 0.269670s, Loss: 0.280513
41,LA_D_6180779,0,23109,0, 37/63, Time: 0.269670s, Loss: 0.280513
24,LA_D_4519635,1,12487,64000, 38/63, Time: 0.269670s, Loss: 0.280513
35,LA_D_5835948,0,64000,0, 39/63, Time: 0.269670s, Loss: 0.280513
21,LA_D_4276413,0,49755,0, 40/63, Time: 0.269670s, Loss: 0.280513
37,LA_D_5891869,0,54006,0, 41/63, Time: 0.269670s, Loss: 0.280513
39,LA_D_5944972,1,39788,64000, 42/63, Time: 0.269670s, Loss: 0.280513
16,LA_D_3457616,0,51111,0, 43/63, Time: 0.269670s, Loss: 0.280513
30,LA_D_5441528,0,24518,0, 44/63, Time: 0.269670s, Loss: 0.280513
26,LA_D_5239066,0,64000,0, 45/63, Time: 0.269670s, Loss: 0.280513
58,LA_D_9566347,0,35349,0, 46/63, Time: 0.269670s, Loss: 0.280513
32,LA_D_5505879,1,35600,64000, 47/63, Time: 0.269670s, Loss: 0.280513
44,LA_D_7095518,0,56482,0, 48/63, Time: 0.269670s, Loss: 0.280513
56,LA_D_9316963,0,58699,0, 49/63, Time: 0.269670s, Loss: 0.280513
3,LA_D_1317561,1,8976,64000, 50/63, Time: 0.269670s, Loss: 0.280513
62,LA_D_9753761,1,22997,64000, 51/63, Time: 0.269670s, Loss: 0.280513
31,LA_D_5505879,0,64000,0, 52/63, Time: 0.269670s, Loss: 0.280513
7,LA_D_1803008,0,45707,0, 53/63, Time: 0.269670s, Loss: 0.280513
50,LA_D_7974256,0,50504,0, 54/63, Time: 0.269670s, Loss: 0.280513
36,LA_D_5835948,1,29523,64000, 55/63, Time: 0.269670s, Loss: 0.280513
48,LA_D_7869978,1,20551,64000, 56/63, Time: 0.269670s, Loss: 0.280513
25,LA_D_4630224,0,27639,0, 57/63, Time: 0.269670s, Loss: 0.280513
5,LA_D_1435765,0,47544,0, 58/63, Time: 0.269670s, Loss: 0.280513
11,LA_D_2648941,1,41414,64000, 59/63, Time: 0.269670s, Loss: 0.280513
17,LA_D_3705418,0,64000,0, 60/63, Time: 0.269670s, Loss: 0.280513
45,LA_D_7452217,0,25016,0, 61/63, Time: 0.269670s, Loss: 0.280513
20,LA_D_4265541,0,26061,0, 62/63, Time: 0.269670s, Loss: 0.280513
0,LA_D_1179848,0,64000,0, 63/63, Time: 0.269670s, Loss: 0.280513
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
52,LA_T_4096754,0,31273,0, 1/118, Time: 0.547320s, Loss: 0.308320
100,LA_T_7550620,0,44981,0, 2/118, Time: 0.547320s, Loss: 0.308320
62,LA_T_5209704,1,34511,64000, 3/118, Time: 0.547320s, Loss: 0.308320
14,LA_T_1836557,0,43646,0, 4/118, Time: 0.547320s, Loss: 0.308320
33,LA_T_3021659,0,64000,0, 5/118, Time: 0.547320s, Loss: 0.308320
49,LA_T_3758169,0,46047,0, 6/118, Time: 0.547320s, Loss: 0.308320
81,LA_T_6521388,0,64000,0, 7/118, Time: 0.547320s, Loss: 0.308320
83,LA_T_6751630,0,62290,0, 8/118, Time: 0.547320s, Loss: 0.308320
99,LA_T_7529623,0,43309,0, 9/118, Time: 0.547320s, Loss: 0.308320
9,LA_T_1589546,1,9736,64000, 10/118, Time: 0.547320s, Loss: 0.308320
72,LA_T_5894355,0,64000,0, 11/118, Time: 0.547320s, Loss: 0.308320
32,LA_T_2995069,0,49112,0, 12/118, Time: 0.547320s, Loss: 0.308320
12,LA_T_1653822,1,9756,64000, 13/118, Time: 0.547320s, Loss: 0.308320
75,LA_T_6331069,0,64000,0, 14/118, Time: 0.547320s, Loss: 0.308320
113,LA_T_9633872,0,27407,0, 15/118, Time: 0.547320s, Loss: 0.308320
103,LA_T_7866363,0,63473,0, 16/118, Time: 0.547320s, Loss: 0.308320
42,LA_T_3467377,0,64000,0, 17/118, Time: 0.547320s, Loss: 0.308320
112,LA_T_9540683,0,25430,0, 18/118, Time: 0.547320s, Loss: 0.308320
110,LA_T_8681550,0,40836,0, 19/118, Time: 0.547320s, Loss: 0.308320
51,LA_T_3993688,0,48709,0, 20/118, Time: 0.547320s, Loss: 0.308320
29,LA_T_2422854,0,62661,0, 21/118, Time: 0.547320s, Loss: 0.308320
111,LA_T_9226984,0,45529,0, 22/118, Time: 0.547320s, Loss: 0.308320
47,LA_T_3627265,0,64000,0, 23/118, Time: 0.547320s, Loss: 0.308320
26,LA_T_2354581,0,47687,0, 24/118, Time: 0.547320s, Loss: 0.308320
46,LA_T_3588714,0,46298,0, 25/118, Time: 0.547320s, Loss: 0.308320
114,LA_T_9668514,0,54564,0, 26/118, Time: 0.547320s, Loss: 0.308320
0,LA_T_1154440,0,30107,0, 27/118, Time: 0.547320s, Loss: 0.308320
77,LA_T_6390981,0,64000,0, 28/118, Time: 0.547320s, Loss: 0.308320
116,LA_T_9746209,1,16967,64000, 29/118, Time: 0.547320s, Loss: 0.308320
76,LA_T_6331069,1,64000,64000, 30/118, Time: 0.547320s, Loss: 0.308320
78,LA_T_6435787,0,43614,0, 31/118, Time: 0.547320s, Loss: 0.308320
80,LA_T_6487227,0,44111,0, 32/118, Time: 0.547320s, Loss: 0.308320
69,LA_T_5786445,0,64000,0, 33/118, Time: 0.547320s, Loss: 0.308320
88,LA_T_7020532,0,59863,0, 34/118, Time: 0.547320s, Loss: 0.308320
13,LA_T_1724943,0,60906,0, 35/118, Time: 0.547320s, Loss: 0.308320
92,LA_T_7273305,0,53173,0, 36/118, Time: 0.547320s, Loss: 0.308320
106,LA_T_8090857,0,64000,0, 37/118, Time: 0.547320s, Loss: 0.308320
7,LA_T_1518499,0,29284,0, 38/118, Time: 0.547320s, Loss: 0.308320
105,LA_T_8007992,0,45465,0, 39/118, Time: 0.547320s, Loss: 0.308320
35,LA_T_3176741,0,62198,0, 40/118, Time: 0.547320s, Loss: 0.308320
79,LA_T_6476207,0,54948,0, 41/118, Time: 0.547320s, Loss: 0.308320
54,LA_T_4584407,0,36921,0, 42/118, Time: 0.547320s, Loss: 0.308320
21,LA_T_2277153,0,64000,0, 43/118, Time: 0.547320s, Loss: 0.308320
56,LA_T_4725126,0,61141,0, 44/118, Time: 0.547320s, Loss: 0.308320
10,LA_T_1630611,0,58109,0, 45/118, Time: 0.547320s, Loss: 0.308320
96,LA_T_7359423,0,50164,0, 46/118, Time: 0.547320s, Loss: 0.308320
98,LA_T_7422011,0,45646,0, 47/118, Time: 0.547320s, Loss: 0.308320
37,LA_T_3189628,1,15851,64000, 48/118, Time: 0.547320s, Loss: 0.308320
95,LA_T_7314513,0,39437,0, 49/118, Time: 0.547320s, Loss: 0.308320
115,LA_T_9746209,0,64000,0, 50/118, Time: 0.547320s, Loss: 0.308320
57,LA_T_4774044,0,59379,0, 51/118, Time: 0.547320s, Loss: 0.308320
20,LA_T_2269038,0,63442,0, 52/118, Time: 0.547320s, Loss: 0.308320
8,LA_T_1589546,0,64000,0, 53/118, Time: 0.547320s, Loss: 0.308320
59,LA_T_5015679,0,41144,0, 54/118, Time: 0.547320s, Loss: 0.308320
17,LA_T_1909651,1,64000,64000, 55/118, Time: 0.547320s, Loss: 0.308320
74,LA_T_6301739,0,41843,0, 56/118, Time: 0.547320s, Loss: 0.308320
64,LA_T_5258800,0,54370,0, 57/118, Time: 0.547320s, Loss: 0.308320
38,LA_T_3220265,0,38149,0, 58/118, Time: 0.547320s, Loss: 0.308320
67,LA_T_5492534,0,28365,0, 59/118, Time: 0.547320s, Loss: 0.308320
3,LA_T_1373588,0,46949,0, 60/118, Time: 0.547320s, Loss: 0.308320
22,LA_T_2277153,1,21822,64000, 61/118, Time: 0.547320s, Loss: 0.308320
82,LA_T_6728875,0,64000,0, 62/118, Time: 0.547320s, Loss: 0.308320
68,LA_T_5522733,0,61381,0, 63/118, Time: 0.547320s, Loss: 0.308320
101,LA_T_7706110,0,24083,0, 64/118, Time: 0.547320s, Loss: 0.308320
2,LA_T_1346935,0,45741,0, 65/118, Time: 0.588676s, Loss: 0.350583
45,LA_T_3527643,1,8295,64000, 66/118, Time: 0.588676s, Loss: 0.350583
108,LA_T_8234484,0,46183,0, 67/118, Time: 0.588676s, Loss: 0.350583
109,LA_T_8527420,0,63377,0, 68/118, Time: 0.588676s, Loss: 0.350583
85,LA_T_6941395,0,64000,0, 69/118, Time: 0.588676s, Loss: 0.350583
65,LA_T_5360018,0,54554,0, 70/118, Time: 0.588676s, Loss: 0.350583
11,LA_T_1653822,0,64000,0, 71/118, Time: 0.588676s, Loss: 0.350583
1,LA_T_1258641,0,44562,0, 72/118, Time: 0.588676s, Loss: 0.350583
66,LA_T_5433188,0,34172,0, 73/118, Time: 0.588676s, Loss: 0.350583
87,LA_T_6960076,0,42296,0, 74/118, Time: 0.588676s, Loss: 0.350583
30,LA_T_2584761,0,47107,0, 75/118, Time: 0.588676s, Loss: 0.350583
24,LA_T_2327393,0,60701,0, 76/118, Time: 0.588676s, Loss: 0.350583
55,LA_T_4630359,0,64000,0, 77/118, Time: 0.588676s, Loss: 0.350583
89,LA_T_7124444,0,64000,0, 78/118, Time: 0.588676s, Loss: 0.350583
48,LA_T_3627265,1,44402,64000, 79/118, Time: 0.588676s, Loss: 0.350583
63,LA_T_5214047,0,41920,0, 80/118, Time: 0.588676s, Loss: 0.350583
5,LA_T_1486451,0,50406,0, 81/118, Time: 0.588676s, Loss: 0.350583
94,LA_T_7281115,1,11690,64000, 82/118, Time: 0.588676s, Loss: 0.350583
86,LA_T_6941395,1,29307,64000, 83/118, Time: 0.588676s, Loss: 0.350583
19,LA_T_2052267,0,38415,0, 84/118, Time: 0.588676s, Loss: 0.350583
117,LA_T_9830298,0,64000,0, 85/118, Time: 0.588676s, Loss: 0.350583
84,LA_T_6822716,0,27313,0, 86/118, Time: 0.588676s, Loss: 0.350583
61,LA_T_5209704,0,64000,0, 87/118, Time: 0.588676s, Loss: 0.350583
60,LA_T_5205025,0,61550,0, 88/118, Time: 0.588676s, Loss: 0.350583
25,LA_T_2333843,0,61708,0, 89/118, Time: 0.588676s, Loss: 0.350583
34,LA_T_3021659,1,10227,64000, 90/118, Time: 0.588676s, Loss: 0.350583
18,LA_T_1909651,2,24481,128000, 91/118, Time: 0.588676s, Loss: 0.350583
70,LA_T_5883755,0,64000,0, 92/118, Time: 0.588676s, Loss: 0.350583
28,LA_T_2419035,1,10625,64000, 93/118, Time: 0.588676s, Loss: 0.350583
23,LA_T_2320617,0,56846,0, 94/118, Time: 0.588676s, Loss: 0.350583
102,LA_T_7808689,0,64000,0, 95/118, Time: 0.588676s, Loss: 0.350583
58,LA_T_4928920,0,64000,0, 96/118, Time: 0.588676s, Loss: 0.350583
16,LA_T_1909651,0,64000,0, 97/118, Time: 0.588676s, Loss: 0.350583
71,LA_T_5883755,1,19926,64000, 98/118, Time: 0.588676s, Loss: 0.350583
44,LA_T_3527643,0,64000,0, 99/118, Time: 0.588676s, Loss: 0.350583
73,LA_T_5978739,0,33363,0, 100/118, Time: 0.588676s, Loss: 0.350583
107,LA_T_8206162,0,55328,0, 101/118, Time: 0.588676s, Loss: 0.350583
27,LA_T_2419035,0,64000,0, 102/118, Time: 0.588676s, Loss: 0.350583
41,LA_T_3391018,0,57402,0, 103/118, Time: 0.588676s, Loss: 0.350583
90,LA_T_7124444,1,21405,64000, 104/118, Time: 0.588676s, Loss: 0.350583
6,LA_T_1490244,0,55572,0, 105/118, Time: 0.588676s, Loss: 0.350583
91,LA_T_7223887,0,40210,0, 106/118, Time: 0.588676s, Loss: 0.350583
15,LA_T_1870524,0,43190,0, 107/118, Time: 0.588676s, Loss: 0.350583
43,LA_T_3467377,1,26131,64000, 108/118, Time: 0.588676s, Loss: 0.350583
40,LA_T_3319380,0,42032,0, 109/118, Time: 0.588676s, Loss: 0.350583
93,LA_T_7281115,0,64000,0, 110/118, Time: 0.588676s, Loss: 0.350583
97,LA_T_7405543,0,36914,0, 111/118, Time: 0.588676s, Loss: 0.350583
4,LA_T_1470918,0,39641,0, 112/118, Time: 0.588676s, Loss: 0.350583
39,LA_T_3250806,0,61271,0, 113/118, Time: 0.588676s, Loss: 0.350583
31,LA_T_2677562,0,63649,0, 114/118, Time: 0.588676s, Loss: 0.350583
50,LA_T_3935691,0,39156,0, 115/118, Time: 0.588676s, Loss: 0.350583
104,LA_T_7888797,0,26626,0, 116/118, Time: 0.588676s, Loss: 0.350583
36,LA_T_3189628,0,64000,0, 117/118, Time: 0.588676s, Loss: 0.350583
53,LA_T_4512109,0,51563,0, 118/118, Time: 0.588676s, Loss: 0.350583
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
31,LA_D_5505879,0,64000,0, 1/63, Time: 0.408060s, Loss: 0.301877
17,LA_D_3705418,0,64000,0, 2/63, Time: 0.408060s, Loss: 0.301877
16,LA_D_3457616,0,51111,0, 3/63, Time: 0.408060s, Loss: 0.301877
21,LA_D_4276413,0,49755,0, 4/63, Time: 0.408060s, Loss: 0.301877
23,LA_D_4519635,0,64000,0, 5/63, Time: 0.408060s, Loss: 0.301877
62,LA_D_9753761,1,22997,64000, 6/63, Time: 0.408060s, Loss: 0.301877
14,LA_D_2949136,1,27301,64000, 7/63, Time: 0.408060s, Loss: 0.301877
7,LA_D_1803008,0,45707,0, 8/63, Time: 0.408060s, Loss: 0.301877
39,LA_D_5944972,1,39788,64000, 9/63, Time: 0.408060s, Loss: 0.301877
6,LA_D_1580841,0,38838,0, 10/63, Time: 0.408060s, Loss: 0.301877
19,LA_D_4013191,0,34443,0, 11/63, Time: 0.408060s, Loss: 0.301877
43,LA_D_7026375,0,61915,0, 12/63, Time: 0.408060s, Loss: 0.301877
32,LA_D_5505879,1,35600,64000, 13/63, Time: 0.408060s, Loss: 0.301877
8,LA_D_1886178,0,40092,0, 14/63, Time: 0.408060s, Loss: 0.301877
45,LA_D_7452217,0,25016,0, 15/63, Time: 0.408060s, Loss: 0.301877
15,LA_D_3203408,0,49607,0, 16/63, Time: 0.408060s, Loss: 0.301877
55,LA_D_9192205,0,40612,0, 17/63, Time: 0.408060s, Loss: 0.301877
29,LA_D_5300881,1,27489,64000, 18/63, Time: 0.408060s, Loss: 0.301877
38,LA_D_5944972,0,64000,0, 19/63, Time: 0.408060s, Loss: 0.301877
10,LA_D_2648941,0,64000,0, 20/63, Time: 0.408060s, Loss: 0.301877
24,LA_D_4519635,1,12487,64000, 21/63, Time: 0.408060s, Loss: 0.301877
49,LA_D_7933136,0,64000,0, 22/63, Time: 0.408060s, Loss: 0.301877
57,LA_D_9493396,0,40904,0, 23/63, Time: 0.408060s, Loss: 0.301877
44,LA_D_7095518,0,56482,0, 24/63, Time: 0.408060s, Loss: 0.301877
37,LA_D_5891869,0,54006,0, 25/63, Time: 0.408060s, Loss: 0.301877
56,LA_D_9316963,0,58699,0, 26/63, Time: 0.408060s, Loss: 0.301877
60,LA_D_9686838,1,28544,64000, 27/63, Time: 0.408060s, Loss: 0.301877
2,LA_D_1317561,0,64000,0, 28/63, Time: 0.408060s, Loss: 0.301877
41,LA_D_6180779,0,23109,0, 29/63, Time: 0.408060s, Loss: 0.301877
1,LA_D_1179848,1,29541,64000, 30/63, Time: 0.408060s, Loss: 0.301877
51,LA_D_8228250,0,42344,0, 31/63, Time: 0.408060s, Loss: 0.301877
33,LA_D_5659407,0,64000,0, 32/63, Time: 0.408060s, Loss: 0.301877
54,LA_D_8998984,0,37498,0, 33/63, Time: 0.408060s, Loss: 0.301877
11,LA_D_2648941,1,41414,64000, 34/63, Time: 0.408060s, Loss: 0.301877
52,LA_D_8284460,0,50174,0, 35/63, Time: 0.408060s, Loss: 0.301877
3,LA_D_1317561,1,8976,64000, 36/63, Time: 0.408060s, Loss: 0.301877
40,LA_D_6055606,0,53176,0, 37/63, Time: 0.408060s, Loss: 0.301877
47,LA_D_7869978,0,64000,0, 38/63, Time: 0.408060s, Loss: 0.301877
20,LA_D_4265541,0,26061,0, 39/63, Time: 0.408060s, Loss: 0.301877
42,LA_D_6502788,0,29166,0, 40/63, Time: 0.408060s, Loss: 0.301877
53,LA_D_8584336,0,61424,0, 41/63, Time: 0.408060s, Loss: 0.301877
9,LA_D_2082512,0,53318,0, 42/63, Time: 0.408060s, Loss: 0.301877
22,LA_D_4394367,0,61722,0, 43/63, Time: 0.408060s, Loss: 0.301877
12,LA_D_2896709,0,64000,0, 44/63, Time: 0.408060s, Loss: 0.301877
25,LA_D_4630224,0,27639,0, 45/63, Time: 0.408060s, Loss: 0.301877
59,LA_D_9686838,0,64000,0, 46/63, Time: 0.408060s, Loss: 0.301877
50,LA_D_7974256,0,50504,0, 47/63, Time: 0.408060s, Loss: 0.301877
30,LA_D_5441528,0,24518,0, 48/63, Time: 0.408060s, Loss: 0.301877
28,LA_D_5300881,0,64000,0, 49/63, Time: 0.408060s, Loss: 0.301877
5,LA_D_1435765,0,47544,0, 50/63, Time: 0.408060s, Loss: 0.301877
34,LA_D_5741681,0,44990,0, 51/63, Time: 0.408060s, Loss: 0.301877
61,LA_D_9753761,0,64000,0, 52/63, Time: 0.408060s, Loss: 0.301877
13,LA_D_2949136,0,64000,0, 53/63, Time: 0.408060s, Loss: 0.301877
18,LA_D_3983088,0,21649,0, 54/63, Time: 0.408060s, Loss: 0.301877
4,LA_D_1366945,0,45986,0, 55/63, Time: 0.408060s, Loss: 0.301877
0,LA_D_1179848,0,64000,0, 56/63, Time: 0.408060s, Loss: 0.301877
27,LA_D_5239066,1,30014,64000, 57/63, Time: 0.408060s, Loss: 0.301877
35,LA_D_5835948,0,64000,0, 58/63, Time: 0.408060s, Loss: 0.301877
58,LA_D_9566347,0,35349,0, 59/63, Time: 0.408060s, Loss: 0.301877
48,LA_D_7869978,1,20551,64000, 60/63, Time: 0.408060s, Loss: 0.301877
36,LA_D_5835948,1,29523,64000, 61/63, Time: 0.408060s, Loss: 0.301877
26,LA_D_5239066,0,64000,0, 62/63, Time: 0.408060s, Loss: 0.301877
46,LA_D_7862876,0,57311,0, 63/63, Time: 0.408060s, Loss: 0.301877
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
84,LA_T_6822716,0,27313,0, 1/118, Time: 0.521370s, Loss: 0.355446
10,LA_T_1630611,0,58109,0, 2/118, Time: 0.521370s, Loss: 0.355446
12,LA_T_1653822,1,9756,64000, 3/118, Time: 0.521370s, Loss: 0.355446
85,LA_T_6941395,0,64000,0, 4/118, Time: 0.521370s, Loss: 0.355446
11,LA_T_1653822,0,64000,0, 5/118, Time: 0.521370s, Loss: 0.355446
108,LA_T_8234484,0,46183,0, 6/118, Time: 0.521370s, Loss: 0.355446
61,LA_T_5209704,0,64000,0, 7/118, Time: 0.521370s, Loss: 0.355446
113,LA_T_9633872,0,27407,0, 8/118, Time: 0.521370s, Loss: 0.355446
60,LA_T_5205025,0,61550,0, 9/118, Time: 0.521370s, Loss: 0.355446
95,LA_T_7314513,0,39437,0, 10/118, Time: 0.521370s, Loss: 0.355446
104,LA_T_7888797,0,26626,0, 11/118, Time: 0.521370s, Loss: 0.355446
51,LA_T_3993688,0,48709,0, 12/118, Time: 0.521370s, Loss: 0.355446
23,LA_T_2320617,0,56846,0, 13/118, Time: 0.521370s, Loss: 0.355446
102,LA_T_7808689,0,64000,0, 14/118, Time: 0.521370s, Loss: 0.355446
16,LA_T_1909651,0,64000,0, 15/118, Time: 0.521370s, Loss: 0.355446
82,LA_T_6728875,0,64000,0, 16/118, Time: 0.521370s, Loss: 0.355446
109,LA_T_8527420,0,63377,0, 17/118, Time: 0.521370s, Loss: 0.355446
65,LA_T_5360018,0,54554,0, 18/118, Time: 0.521370s, Loss: 0.355446
21,LA_T_2277153,0,64000,0, 19/118, Time: 0.521370s, Loss: 0.355446
66,LA_T_5433188,0,34172,0, 20/118, Time: 0.521370s, Loss: 0.355446
67,LA_T_5492534,0,28365,0, 21/118, Time: 0.521370s, Loss: 0.355446
13,LA_T_1724943,0,60906,0, 22/118, Time: 0.521370s, Loss: 0.355446
38,LA_T_3220265,0,38149,0, 23/118, Time: 0.521370s, Loss: 0.355446
18,LA_T_1909651,2,24481,128000, 24/118, Time: 0.521370s, Loss: 0.355446
44,LA_T_3527643,0,64000,0, 25/118, Time: 0.521370s, Loss: 0.355446
31,LA_T_2677562,0,63649,0, 26/118, Time: 0.521370s, Loss: 0.355446
22,LA_T_2277153,1,21822,64000, 27/118, Time: 0.521370s, Loss: 0.355446
79,LA_T_6476207,0,54948,0, 28/118, Time: 0.521370s, Loss: 0.355446
25,LA_T_2333843,0,61708,0, 29/118, Time: 0.521370s, Loss: 0.355446
117,LA_T_9830298,0,64000,0, 30/118, Time: 0.521370s, Loss: 0.355446
83,LA_T_6751630,0,62290,0, 31/118, Time: 0.521370s, Loss: 0.355446
115,LA_T_9746209,0,64000,0, 32/118, Time: 0.521370s, Loss: 0.355446
110,LA_T_8681550,0,40836,0, 33/118, Time: 0.521370s, Loss: 0.355446
64,LA_T_5258800,0,54370,0, 34/118, Time: 0.521370s, Loss: 0.355446
5,LA_T_1486451,0,50406,0, 35/118, Time: 0.521370s, Loss: 0.355446
42,LA_T_3467377,0,64000,0, 36/118, Time: 0.521370s, Loss: 0.355446
73,LA_T_5978739,0,33363,0, 37/118, Time: 0.521370s, Loss: 0.355446
76,LA_T_6331069,1,64000,64000, 38/118, Time: 0.521370s, Loss: 0.355446
100,LA_T_7550620,0,44981,0, 39/118, Time: 0.521370s, Loss: 0.355446
58,LA_T_4928920,0,64000,0, 40/118, Time: 0.521370s, Loss: 0.355446
107,LA_T_8206162,0,55328,0, 41/118, Time: 0.521370s, Loss: 0.355446
8,LA_T_1589546,0,64000,0, 42/118, Time: 0.521370s, Loss: 0.355446
101,LA_T_7706110,0,24083,0, 43/118, Time: 0.521370s, Loss: 0.355446
1,LA_T_1258641,0,44562,0, 44/118, Time: 0.521370s, Loss: 0.355446
45,LA_T_3527643,1,8295,64000, 45/118, Time: 0.521370s, Loss: 0.355446
106,LA_T_8090857,0,64000,0, 46/118, Time: 0.521370s, Loss: 0.355446
19,LA_T_2052267,0,38415,0, 47/118, Time: 0.521370s, Loss: 0.355446
71,LA_T_5883755,1,19926,64000, 48/118, Time: 0.521370s, Loss: 0.355446
92,LA_T_7273305,0,53173,0, 49/118, Time: 0.521370s, Loss: 0.355446
69,LA_T_5786445,0,64000,0, 50/118, Time: 0.521370s, Loss: 0.355446
116,LA_T_9746209,1,16967,64000, 51/118, Time: 0.521370s, Loss: 0.355446
86,LA_T_6941395,1,29307,64000, 52/118, Time: 0.521370s, Loss: 0.355446
98,LA_T_7422011,0,45646,0, 53/118, Time: 0.521370s, Loss: 0.355446
87,LA_T_6960076,0,42296,0, 54/118, Time: 0.521370s, Loss: 0.355446
54,LA_T_4584407,0,36921,0, 55/118, Time: 0.521370s, Loss: 0.355446
55,LA_T_4630359,0,64000,0, 56/118, Time: 0.521370s, Loss: 0.355446
94,LA_T_7281115,1,11690,64000, 57/118, Time: 0.521370s, Loss: 0.355446
36,LA_T_3189628,0,64000,0, 58/118, Time: 0.521370s, Loss: 0.355446
78,LA_T_6435787,0,43614,0, 59/118, Time: 0.521370s, Loss: 0.355446
90,LA_T_7124444,1,21405,64000, 60/118, Time: 0.521370s, Loss: 0.355446
6,LA_T_1490244,0,55572,0, 61/118, Time: 0.521370s, Loss: 0.355446
0,LA_T_1154440,0,30107,0, 62/118, Time: 0.521370s, Loss: 0.355446
75,LA_T_6331069,0,64000,0, 63/118, Time: 0.521370s, Loss: 0.355446
103,LA_T_7866363,0,63473,0, 64/118, Time: 0.521370s, Loss: 0.355446
114,LA_T_9668514,0,54564,0, 65/118, Time: 0.562996s, Loss: 0.329291
17,LA_T_1909651,1,64000,64000, 66/118, Time: 0.562996s, Loss: 0.329291
41,LA_T_3391018,0,57402,0, 67/118, Time: 0.562996s, Loss: 0.329291
59,LA_T_5015679,0,41144,0, 68/118, Time: 0.562996s, Loss: 0.329291
88,LA_T_7020532,0,59863,0, 69/118, Time: 0.562996s, Loss: 0.329291
53,LA_T_4512109,0,51563,0, 70/118, Time: 0.562996s, Loss: 0.329291
34,LA_T_3021659,1,10227,64000, 71/118, Time: 0.562996s, Loss: 0.329291
35,LA_T_3176741,0,62198,0, 72/118, Time: 0.562996s, Loss: 0.329291
57,LA_T_4774044,0,59379,0, 73/118, Time: 0.562996s, Loss: 0.329291
74,LA_T_6301739,0,41843,0, 74/118, Time: 0.562996s, Loss: 0.329291
52,LA_T_4096754,0,31273,0, 75/118, Time: 0.562996s, Loss: 0.329291
4,LA_T_1470918,0,39641,0, 76/118, Time: 0.562996s, Loss: 0.329291
50,LA_T_3935691,0,39156,0, 77/118, Time: 0.562996s, Loss: 0.329291
37,LA_T_3189628,1,15851,64000, 78/118, Time: 0.562996s, Loss: 0.329291
28,LA_T_2419035,1,10625,64000, 79/118, Time: 0.562996s, Loss: 0.329291
89,LA_T_7124444,0,64000,0, 80/118, Time: 0.562996s, Loss: 0.329291
2,LA_T_1346935,0,45741,0, 81/118, Time: 0.562996s, Loss: 0.329291
20,LA_T_2269038,0,63442,0, 82/118, Time: 0.562996s, Loss: 0.329291
29,LA_T_2422854,0,62661,0, 83/118, Time: 0.562996s, Loss: 0.329291
97,LA_T_7405543,0,36914,0, 84/118, Time: 0.562996s, Loss: 0.329291
14,LA_T_1836557,0,43646,0, 85/118, Time: 0.562996s, Loss: 0.329291
27,LA_T_2419035,0,64000,0, 86/118, Time: 0.562996s, Loss: 0.329291
48,LA_T_3627265,1,44402,64000, 87/118, Time: 0.562996s, Loss: 0.329291
7,LA_T_1518499,0,29284,0, 88/118, Time: 0.562996s, Loss: 0.329291
96,LA_T_7359423,0,50164,0, 89/118, Time: 0.562996s, Loss: 0.329291
15,LA_T_1870524,0,43190,0, 90/118, Time: 0.562996s, Loss: 0.329291
56,LA_T_4725126,0,61141,0, 91/118, Time: 0.562996s, Loss: 0.329291
32,LA_T_2995069,0,49112,0, 92/118, Time: 0.562996s, Loss: 0.329291
70,LA_T_5883755,0,64000,0, 93/118, Time: 0.562996s, Loss: 0.329291
46,LA_T_3588714,0,46298,0, 94/118, Time: 0.562996s, Loss: 0.329291
63,LA_T_5214047,0,41920,0, 95/118, Time: 0.562996s, Loss: 0.329291
80,LA_T_6487227,0,44111,0, 96/118, Time: 0.562996s, Loss: 0.329291
49,LA_T_3758169,0,46047,0, 97/118, Time: 0.562996s, Loss: 0.329291
105,LA_T_8007992,0,45465,0, 98/118, Time: 0.562996s, Loss: 0.329291
30,LA_T_2584761,0,47107,0, 99/118, Time: 0.562996s, Loss: 0.329291
3,LA_T_1373588,0,46949,0, 100/118, Time: 0.562996s, Loss: 0.329291
81,LA_T_6521388,0,64000,0, 101/118, Time: 0.562996s, Loss: 0.329291
77,LA_T_6390981,0,64000,0, 102/118, Time: 0.562996s, Loss: 0.329291
72,LA_T_5894355,0,64000,0, 103/118, Time: 0.562996s, Loss: 0.329291
111,LA_T_9226984,0,45529,0, 104/118, Time: 0.562996s, Loss: 0.329291
33,LA_T_3021659,0,64000,0, 105/118, Time: 0.562996s, Loss: 0.329291
62,LA_T_5209704,1,34511,64000, 106/118, Time: 0.562996s, Loss: 0.329291
47,LA_T_3627265,0,64000,0, 107/118, Time: 0.562996s, Loss: 0.329291
24,LA_T_2327393,0,60701,0, 108/118, Time: 0.562996s, Loss: 0.329291
99,LA_T_7529623,0,43309,0, 109/118, Time: 0.562996s, Loss: 0.329291
26,LA_T_2354581,0,47687,0, 110/118, Time: 0.562996s, Loss: 0.329291
68,LA_T_5522733,0,61381,0, 111/118, Time: 0.562996s, Loss: 0.329291
112,LA_T_9540683,0,25430,0, 112/118, Time: 0.562996s, Loss: 0.329291
43,LA_T_3467377,1,26131,64000, 113/118, Time: 0.562996s, Loss: 0.329291
93,LA_T_7281115,0,64000,0, 114/118, Time: 0.562996s, Loss: 0.329291
40,LA_T_3319380,0,42032,0, 115/118, Time: 0.562996s, Loss: 0.329291
9,LA_T_1589546,1,9736,64000, 116/118, Time: 0.562996s, Loss: 0.329291
91,LA_T_7223887,0,40210,0, 117/118, Time: 0.562996s, Loss: 0.329291
39,LA_T_3250806,0,61271,0, 118/118, Time: 0.562996s, Loss: 0.329291
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
14,LA_D_2949136,1,27301,64000, 1/63, Time: 0.441130s, Loss: 0.288252
56,LA_D_9316963,0,58699,0, 2/63, Time: 0.441130s, Loss: 0.288252
51,LA_D_8228250,0,42344,0, 3/63, Time: 0.441130s, Loss: 0.288252
2,LA_D_1317561,0,64000,0, 4/63, Time: 0.441130s, Loss: 0.288252
18,LA_D_3983088,0,21649,0, 5/63, Time: 0.441130s, Loss: 0.288252
36,LA_D_5835948,1,29523,64000, 6/63, Time: 0.441130s, Loss: 0.288252
27,LA_D_5239066,1,30014,64000, 7/63, Time: 0.441130s, Loss: 0.288252
42,LA_D_6502788,0,29166,0, 8/63, Time: 0.441130s, Loss: 0.288252
37,LA_D_5891869,0,54006,0, 9/63, Time: 0.441130s, Loss: 0.288252
17,LA_D_3705418,0,64000,0, 10/63, Time: 0.441130s, Loss: 0.288252
44,LA_D_7095518,0,56482,0, 11/63, Time: 0.441130s, Loss: 0.288252
23,LA_D_4519635,0,64000,0, 12/63, Time: 0.441130s, Loss: 0.288252
43,LA_D_7026375,0,61915,0, 13/63, Time: 0.441130s, Loss: 0.288252
46,LA_D_7862876,0,57311,0, 14/63, Time: 0.441130s, Loss: 0.288252
33,LA_D_5659407,0,64000,0, 15/63, Time: 0.441130s, Loss: 0.288252
47,LA_D_7869978,0,64000,0, 16/63, Time: 0.441130s, Loss: 0.288252
48,LA_D_7869978,1,20551,64000, 17/63, Time: 0.441130s, Loss: 0.288252
57,LA_D_9493396,0,40904,0, 18/63, Time: 0.441130s, Loss: 0.288252
50,LA_D_7974256,0,50504,0, 19/63, Time: 0.441130s, Loss: 0.288252
5,LA_D_1435765,0,47544,0, 20/63, Time: 0.441130s, Loss: 0.288252
7,LA_D_1803008,0,45707,0, 21/63, Time: 0.441130s, Loss: 0.288252
12,LA_D_2896709,0,64000,0, 22/63, Time: 0.441130s, Loss: 0.288252
26,LA_D_5239066,0,64000,0, 23/63, Time: 0.441130s, Loss: 0.288252
53,LA_D_8584336,0,61424,0, 24/63, Time: 0.441130s, Loss: 0.288252
9,LA_D_2082512,0,53318,0, 25/63, Time: 0.441130s, Loss: 0.288252
10,LA_D_2648941,0,64000,0, 26/63, Time: 0.441130s, Loss: 0.288252
22,LA_D_4394367,0,61722,0, 27/63, Time: 0.441130s, Loss: 0.288252
28,LA_D_5300881,0,64000,0, 28/63, Time: 0.441130s, Loss: 0.288252
60,LA_D_9686838,1,28544,64000, 29/63, Time: 0.441130s, Loss: 0.288252
24,LA_D_4519635,1,12487,64000, 30/63, Time: 0.441130s, Loss: 0.288252
38,LA_D_5944972,0,64000,0, 31/63, Time: 0.441130s, Loss: 0.288252
15,LA_D_3203408,0,49607,0, 32/63, Time: 0.441130s, Loss: 0.288252
29,LA_D_5300881,1,27489,64000, 33/63, Time: 0.441130s, Loss: 0.288252
0,LA_D_1179848,0,64000,0, 34/63, Time: 0.441130s, Loss: 0.288252
19,LA_D_4013191,0,34443,0, 35/63, Time: 0.441130s, Loss: 0.288252
59,LA_D_9686838,0,64000,0, 36/63, Time: 0.441130s, Loss: 0.288252
54,LA_D_8998984,0,37498,0, 37/63, Time: 0.441130s, Loss: 0.288252
16,LA_D_3457616,0,51111,0, 38/63, Time: 0.441130s, Loss: 0.288252
3,LA_D_1317561,1,8976,64000, 39/63, Time: 0.441130s, Loss: 0.288252
35,LA_D_5835948,0,64000,0, 40/63, Time: 0.441130s, Loss: 0.288252
58,LA_D_9566347,0,35349,0, 41/63, Time: 0.441130s, Loss: 0.288252
41,LA_D_6180779,0,23109,0, 42/63, Time: 0.441130s, Loss: 0.288252
13,LA_D_2949136,0,64000,0, 43/63, Time: 0.441130s, Loss: 0.288252
32,LA_D_5505879,1,35600,64000, 44/63, Time: 0.441130s, Loss: 0.288252
40,LA_D_6055606,0,53176,0, 45/63, Time: 0.441130s, Loss: 0.288252
62,LA_D_9753761,1,22997,64000, 46/63, Time: 0.441130s, Loss: 0.288252
61,LA_D_9753761,0,64000,0, 47/63, Time: 0.441130s, Loss: 0.288252
1,LA_D_1179848,1,29541,64000, 48/63, Time: 0.441130s, Loss: 0.288252
11,LA_D_2648941,1,41414,64000, 49/63, Time: 0.441130s, Loss: 0.288252
31,LA_D_5505879,0,64000,0, 50/63, Time: 0.441130s, Loss: 0.288252
34,LA_D_5741681,0,44990,0, 51/63, Time: 0.441130s, Loss: 0.288252
52,LA_D_8284460,0,50174,0, 52/63, Time: 0.441130s, Loss: 0.288252
49,LA_D_7933136,0,64000,0, 53/63, Time: 0.441130s, Loss: 0.288252
20,LA_D_4265541,0,26061,0, 54/63, Time: 0.441130s, Loss: 0.288252
25,LA_D_4630224,0,27639,0, 55/63, Time: 0.441130s, Loss: 0.288252
8,LA_D_1886178,0,40092,0, 56/63, Time: 0.441130s, Loss: 0.288252
4,LA_D_1366945,0,45986,0, 57/63, Time: 0.441130s, Loss: 0.288252
55,LA_D_9192205,0,40612,0, 58/63, Time: 0.441130s, Loss: 0.288252
6,LA_D_1580841,0,38838,0, 59/63, Time: 0.441130s, Loss: 0.288252
21,LA_D_4276413,0,49755,0, 60/63, Time: 0.441130s, Loss: 0.288252
30,LA_D_5441528,0,24518,0, 61/63, Time: 0.441130s, Loss: 0.288252
39,LA_D_5944972,1,39788,64000, 62/63, Time: 0.441130s, Loss: 0.288252
45,LA_D_7452217,0,25016,0, 63/63, Time: 0.441130s, Loss: 0.288252
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
35,LA_T_3176741,0,62198,0, 1/118, Time: 0.542603s, Loss: 0.318610
106,LA_T_8090857,0,64000,0, 2/118, Time: 0.542603s, Loss: 0.318610
33,LA_T_3021659,0,64000,0, 3/118, Time: 0.542603s, Loss: 0.318610
115,LA_T_9746209,0,64000,0, 4/118, Time: 0.542603s, Loss: 0.318610
18,LA_T_1909651,2,24481,128000, 5/118, Time: 0.542603s, Loss: 0.318610
4,LA_T_1470918,0,39641,0, 6/118, Time: 0.542603s, Loss: 0.318610
82,LA_T_6728875,0,64000,0, 7/118, Time: 0.542603s, Loss: 0.318610
87,LA_T_6960076,0,42296,0, 8/118, Time: 0.542603s, Loss: 0.318610
40,LA_T_3319380,0,42032,0, 9/118, Time: 0.542603s, Loss: 0.318610
91,LA_T_7223887,0,40210,0, 10/118, Time: 0.542603s, Loss: 0.318610
70,LA_T_5883755,0,64000,0, 11/118, Time: 0.542603s, Loss: 0.318610
80,LA_T_6487227,0,44111,0, 12/118, Time: 0.542603s, Loss: 0.318610
19,LA_T_2052267,0,38415,0, 13/118, Time: 0.542603s, Loss: 0.318610
74,LA_T_6301739,0,41843,0, 14/118, Time: 0.542603s, Loss: 0.318610
58,LA_T_4928920,0,64000,0, 15/118, Time: 0.542603s, Loss: 0.318610
47,LA_T_3627265,0,64000,0, 16/118, Time: 0.542603s, Loss: 0.318610
36,LA_T_3189628,0,64000,0, 17/118, Time: 0.542603s, Loss: 0.318610
0,LA_T_1154440,0,30107,0, 18/118, Time: 0.542603s, Loss: 0.318610
98,LA_T_7422011,0,45646,0, 19/118, Time: 0.542603s, Loss: 0.318610
15,LA_T_1870524,0,43190,0, 20/118, Time: 0.542603s, Loss: 0.318610
62,LA_T_5209704,1,34511,64000, 21/118, Time: 0.542603s, Loss: 0.318610
5,LA_T_1486451,0,50406,0, 22/118, Time: 0.542603s, Loss: 0.318610
48,LA_T_3627265,1,44402,64000, 23/118, Time: 0.542603s, Loss: 0.318610
56,LA_T_4725126,0,61141,0, 24/118, Time: 0.542603s, Loss: 0.318610
59,LA_T_5015679,0,41144,0, 25/118, Time: 0.542603s, Loss: 0.318610
66,LA_T_5433188,0,34172,0, 26/118, Time: 0.542603s, Loss: 0.318610
99,LA_T_7529623,0,43309,0, 27/118, Time: 0.542603s, Loss: 0.318610
71,LA_T_5883755,1,19926,64000, 28/118, Time: 0.542603s, Loss: 0.318610
113,LA_T_9633872,0,27407,0, 29/118, Time: 0.542603s, Loss: 0.318610
114,LA_T_9668514,0,54564,0, 30/118, Time: 0.542603s, Loss: 0.318610
110,LA_T_8681550,0,40836,0, 31/118, Time: 0.542603s, Loss: 0.318610
13,LA_T_1724943,0,60906,0, 32/118, Time: 0.542603s, Loss: 0.318610
34,LA_T_3021659,1,10227,64000, 33/118, Time: 0.542603s, Loss: 0.318610
61,LA_T_5209704,0,64000,0, 34/118, Time: 0.542603s, Loss: 0.318610
73,LA_T_5978739,0,33363,0, 35/118, Time: 0.542603s, Loss: 0.318610
86,LA_T_6941395,1,29307,64000, 36/118, Time: 0.542603s, Loss: 0.318610
116,LA_T_9746209,1,16967,64000, 37/118, Time: 0.542603s, Loss: 0.318610
68,LA_T_5522733,0,61381,0, 38/118, Time: 0.542603s, Loss: 0.318610
60,LA_T_5205025,0,61550,0, 39/118, Time: 0.542603s, Loss: 0.318610
85,LA_T_6941395,0,64000,0, 40/118, Time: 0.542603s, Loss: 0.318610
31,LA_T_2677562,0,63649,0, 41/118, Time: 0.542603s, Loss: 0.318610
42,LA_T_3467377,0,64000,0, 42/118, Time: 0.542603s, Loss: 0.318610
2,LA_T_1346935,0,45741,0, 43/118, Time: 0.542603s, Loss: 0.318610
6,LA_T_1490244,0,55572,0, 44/118, Time: 0.542603s, Loss: 0.318610
55,LA_T_4630359,0,64000,0, 45/118, Time: 0.542603s, Loss: 0.318610
8,LA_T_1589546,0,64000,0, 46/118, Time: 0.542603s, Loss: 0.318610
53,LA_T_4512109,0,51563,0, 47/118, Time: 0.542603s, Loss: 0.318610
89,LA_T_7124444,0,64000,0, 48/118, Time: 0.542603s, Loss: 0.318610
7,LA_T_1518499,0,29284,0, 49/118, Time: 0.542603s, Loss: 0.318610
64,LA_T_5258800,0,54370,0, 50/118, Time: 0.542603s, Loss: 0.318610
109,LA_T_8527420,0,63377,0, 51/118, Time: 0.542603s, Loss: 0.318610
96,LA_T_7359423,0,50164,0, 52/118, Time: 0.542603s, Loss: 0.318610
90,LA_T_7124444,1,21405,64000, 53/118, Time: 0.542603s, Loss: 0.318610
79,LA_T_6476207,0,54948,0, 54/118, Time: 0.542603s, Loss: 0.318610
72,LA_T_5894355,0,64000,0, 55/118, Time: 0.542603s, Loss: 0.318610
75,LA_T_6331069,0,64000,0, 56/118, Time: 0.542603s, Loss: 0.318610
94,LA_T_7281115,1,11690,64000, 57/118, Time: 0.542603s, Loss: 0.318610
37,LA_T_3189628,1,15851,64000, 58/118, Time: 0.542603s, Loss: 0.318610
88,LA_T_7020532,0,59863,0, 59/118, Time: 0.542603s, Loss: 0.318610
65,LA_T_5360018,0,54554,0, 60/118, Time: 0.542603s, Loss: 0.318610
43,LA_T_3467377,1,26131,64000, 61/118, Time: 0.542603s, Loss: 0.318610
104,LA_T_7888797,0,26626,0, 62/118, Time: 0.542603s, Loss: 0.318610
67,LA_T_5492534,0,28365,0, 63/118, Time: 0.542603s, Loss: 0.318610
101,LA_T_7706110,0,24083,0, 64/118, Time: 0.542603s, Loss: 0.318610
77,LA_T_6390981,0,64000,0, 65/118, Time: 0.547185s, Loss: 0.377963
105,LA_T_8007992,0,45465,0, 66/118, Time: 0.547185s, Loss: 0.377963
81,LA_T_6521388,0,64000,0, 67/118, Time: 0.547185s, Loss: 0.377963
52,LA_T_4096754,0,31273,0, 68/118, Time: 0.547185s, Loss: 0.377963
20,LA_T_2269038,0,63442,0, 69/118, Time: 0.547185s, Loss: 0.377963
3,LA_T_1373588,0,46949,0, 70/118, Time: 0.547185s, Loss: 0.377963
111,LA_T_9226984,0,45529,0, 71/118, Time: 0.547185s, Loss: 0.377963
23,LA_T_2320617,0,56846,0, 72/118, Time: 0.547185s, Loss: 0.377963
41,LA_T_3391018,0,57402,0, 73/118, Time: 0.547185s, Loss: 0.377963
30,LA_T_2584761,0,47107,0, 74/118, Time: 0.547185s, Loss: 0.377963
54,LA_T_4584407,0,36921,0, 75/118, Time: 0.547185s, Loss: 0.377963
11,LA_T_1653822,0,64000,0, 76/118, Time: 0.547185s, Loss: 0.377963
76,LA_T_6331069,1,64000,64000, 77/118, Time: 0.547185s, Loss: 0.377963
14,LA_T_1836557,0,43646,0, 78/118, Time: 0.547185s, Loss: 0.377963
50,LA_T_3935691,0,39156,0, 79/118, Time: 0.547185s, Loss: 0.377963
107,LA_T_8206162,0,55328,0, 80/118, Time: 0.547185s, Loss: 0.377963
39,LA_T_3250806,0,61271,0, 81/118, Time: 0.547185s, Loss: 0.377963
10,LA_T_1630611,0,58109,0, 82/118, Time: 0.547185s, Loss: 0.377963
44,LA_T_3527643,0,64000,0, 83/118, Time: 0.547185s, Loss: 0.377963
63,LA_T_5214047,0,41920,0, 84/118, Time: 0.547185s, Loss: 0.377963
84,LA_T_6822716,0,27313,0, 85/118, Time: 0.547185s, Loss: 0.377963
24,LA_T_2327393,0,60701,0, 86/118, Time: 0.547185s, Loss: 0.377963
108,LA_T_8234484,0,46183,0, 87/118, Time: 0.547185s, Loss: 0.377963
9,LA_T_1589546,1,9736,64000, 88/118, Time: 0.547185s, Loss: 0.377963
21,LA_T_2277153,0,64000,0, 89/118, Time: 0.547185s, Loss: 0.377963
117,LA_T_9830298,0,64000,0, 90/118, Time: 0.547185s, Loss: 0.377963
46,LA_T_3588714,0,46298,0, 91/118, Time: 0.547185s, Loss: 0.377963
38,LA_T_3220265,0,38149,0, 92/118, Time: 0.547185s, Loss: 0.377963
83,LA_T_6751630,0,62290,0, 93/118, Time: 0.547185s, Loss: 0.377963
1,LA_T_1258641,0,44562,0, 94/118, Time: 0.547185s, Loss: 0.377963
51,LA_T_3993688,0,48709,0, 95/118, Time: 0.547185s, Loss: 0.377963
32,LA_T_2995069,0,49112,0, 96/118, Time: 0.547185s, Loss: 0.377963
92,LA_T_7273305,0,53173,0, 97/118, Time: 0.547185s, Loss: 0.377963
57,LA_T_4774044,0,59379,0, 98/118, Time: 0.547185s, Loss: 0.377963
16,LA_T_1909651,0,64000,0, 99/118, Time: 0.547185s, Loss: 0.377963
95,LA_T_7314513,0,39437,0, 100/118, Time: 0.547185s, Loss: 0.377963
17,LA_T_1909651,1,64000,64000, 101/118, Time: 0.547185s, Loss: 0.377963
102,LA_T_7808689,0,64000,0, 102/118, Time: 0.547185s, Loss: 0.377963
49,LA_T_3758169,0,46047,0, 103/118, Time: 0.547185s, Loss: 0.377963
12,LA_T_1653822,1,9756,64000, 104/118, Time: 0.547185s, Loss: 0.377963
112,LA_T_9540683,0,25430,0, 105/118, Time: 0.547185s, Loss: 0.377963
22,LA_T_2277153,1,21822,64000, 106/118, Time: 0.547185s, Loss: 0.377963
69,LA_T_5786445,0,64000,0, 107/118, Time: 0.547185s, Loss: 0.377963
78,LA_T_6435787,0,43614,0, 108/118, Time: 0.547185s, Loss: 0.377963
93,LA_T_7281115,0,64000,0, 109/118, Time: 0.547185s, Loss: 0.377963
45,LA_T_3527643,1,8295,64000, 110/118, Time: 0.547185s, Loss: 0.377963
100,LA_T_7550620,0,44981,0, 111/118, Time: 0.547185s, Loss: 0.377963
25,LA_T_2333843,0,61708,0, 112/118, Time: 0.547185s, Loss: 0.377963
103,LA_T_7866363,0,63473,0, 113/118, Time: 0.547185s, Loss: 0.377963
26,LA_T_2354581,0,47687,0, 114/118, Time: 0.547185s, Loss: 0.377963
97,LA_T_7405543,0,36914,0, 115/118, Time: 0.547185s, Loss: 0.377963
28,LA_T_2419035,1,10625,64000, 116/118, Time: 0.547185s, Loss: 0.377963
29,LA_T_2422854,0,62661,0, 117/118, Time: 0.547185s, Loss: 0.377963
27,LA_T_2419035,0,64000,0, 118/118, Time: 0.547185s, Loss: 0.377963
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
23,LA_D_4519635,0,64000,0, 1/63, Time: 0.265095s, Loss: 0.273731
14,LA_D_2949136,1,27301,64000, 2/63, Time: 0.265095s, Loss: 0.273731
62,LA_D_9753761,1,22997,64000, 3/63, Time: 0.265095s, Loss: 0.273731
21,LA_D_4276413,0,49755,0, 4/63, Time: 0.265095s, Loss: 0.273731
16,LA_D_3457616,0,51111,0, 5/63, Time: 0.265095s, Loss: 0.273731
39,LA_D_5944972,1,39788,64000, 6/63, Time: 0.265095s, Loss: 0.273731
6,LA_D_1580841,0,38838,0, 7/63, Time: 0.265095s, Loss: 0.273731
33,LA_D_5659407,0,64000,0, 8/63, Time: 0.265095s, Loss: 0.273731
13,LA_D_2949136,0,64000,0, 9/63, Time: 0.265095s, Loss: 0.273731
46,LA_D_7862876,0,57311,0, 10/63, Time: 0.265095s, Loss: 0.273731
15,LA_D_3203408,0,49607,0, 11/63, Time: 0.265095s, Loss: 0.273731
29,LA_D_5300881,1,27489,64000, 12/63, Time: 0.265095s, Loss: 0.273731
40,LA_D_6055606,0,53176,0, 13/63, Time: 0.265095s, Loss: 0.273731
24,LA_D_4519635,1,12487,64000, 14/63, Time: 0.265095s, Loss: 0.273731
0,LA_D_1179848,0,64000,0, 15/63, Time: 0.265095s, Loss: 0.273731
32,LA_D_5505879,1,35600,64000, 16/63, Time: 0.265095s, Loss: 0.273731
9,LA_D_2082512,0,53318,0, 17/63, Time: 0.265095s, Loss: 0.273731
36,LA_D_5835948,1,29523,64000, 18/63, Time: 0.265095s, Loss: 0.273731
57,LA_D_9493396,0,40904,0, 19/63, Time: 0.265095s, Loss: 0.273731
34,LA_D_5741681,0,44990,0, 20/63, Time: 0.265095s, Loss: 0.273731
60,LA_D_9686838,1,28544,64000, 21/63, Time: 0.265095s, Loss: 0.273731
12,LA_D_2896709,0,64000,0, 22/63, Time: 0.265095s, Loss: 0.273731
1,LA_D_1179848,1,29541,64000, 23/63, Time: 0.265095s, Loss: 0.273731
4,LA_D_1366945,0,45986,0, 24/63, Time: 0.265095s, Loss: 0.273731
2,LA_D_1317561,0,64000,0, 25/63, Time: 0.265095s, Loss: 0.273731
25,LA_D_4630224,0,27639,0, 26/63, Time: 0.265095s, Loss: 0.273731
54,LA_D_8998984,0,37498,0, 27/63, Time: 0.265095s, Loss: 0.273731
37,LA_D_5891869,0,54006,0, 28/63, Time: 0.265095s, Loss: 0.273731
26,LA_D_5239066,0,64000,0, 29/63, Time: 0.265095s, Loss: 0.273731
41,LA_D_6180779,0,23109,0, 30/63, Time: 0.265095s, Loss: 0.273731
27,LA_D_5239066,1,30014,64000, 31/63, Time: 0.265095s, Loss: 0.273731
44,LA_D_7095518,0,56482,0, 32/63, Time: 0.265095s, Loss: 0.273731
10,LA_D_2648941,0,64000,0, 33/63, Time: 0.265095s, Loss: 0.273731
43,LA_D_7026375,0,61915,0, 34/63, Time: 0.265095s, Loss: 0.273731
58,LA_D_9566347,0,35349,0, 35/63, Time: 0.265095s, Loss: 0.273731
42,LA_D_6502788,0,29166,0, 36/63, Time: 0.265095s, Loss: 0.273731
28,LA_D_5300881,0,64000,0, 37/63, Time: 0.265095s, Loss: 0.273731
48,LA_D_7869978,1,20551,64000, 38/63, Time: 0.265095s, Loss: 0.273731
53,LA_D_8584336,0,61424,0, 39/63, Time: 0.265095s, Loss: 0.273731
20,LA_D_4265541,0,26061,0, 40/63, Time: 0.265095s, Loss: 0.273731
18,LA_D_3983088,0,21649,0, 41/63, Time: 0.265095s, Loss: 0.273731
59,LA_D_9686838,0,64000,0, 42/63, Time: 0.265095s, Loss: 0.273731
35,LA_D_5835948,0,64000,0, 43/63, Time: 0.265095s, Loss: 0.273731
7,LA_D_1803008,0,45707,0, 44/63, Time: 0.265095s, Loss: 0.273731
11,LA_D_2648941,1,41414,64000, 45/63, Time: 0.265095s, Loss: 0.273731
5,LA_D_1435765,0,47544,0, 46/63, Time: 0.265095s, Loss: 0.273731
55,LA_D_9192205,0,40612,0, 47/63, Time: 0.265095s, Loss: 0.273731
49,LA_D_7933136,0,64000,0, 48/63, Time: 0.265095s, Loss: 0.273731
47,LA_D_7869978,0,64000,0, 49/63, Time: 0.265095s, Loss: 0.273731
3,LA_D_1317561,1,8976,64000, 50/63, Time: 0.265095s, Loss: 0.273731
38,LA_D_5944972,0,64000,0, 51/63, Time: 0.265095s, Loss: 0.273731
52,LA_D_8284460,0,50174,0, 52/63, Time: 0.265095s, Loss: 0.273731
19,LA_D_4013191,0,34443,0, 53/63, Time: 0.265095s, Loss: 0.273731
51,LA_D_8228250,0,42344,0, 54/63, Time: 0.265095s, Loss: 0.273731
61,LA_D_9753761,0,64000,0, 55/63, Time: 0.265095s, Loss: 0.273731
45,LA_D_7452217,0,25016,0, 56/63, Time: 0.265095s, Loss: 0.273731
31,LA_D_5505879,0,64000,0, 57/63, Time: 0.265095s, Loss: 0.273731
17,LA_D_3705418,0,64000,0, 58/63, Time: 0.265095s, Loss: 0.273731
8,LA_D_1886178,0,40092,0, 59/63, Time: 0.265095s, Loss: 0.273731
56,LA_D_9316963,0,58699,0, 60/63, Time: 0.265095s, Loss: 0.273731
22,LA_D_4394367,0,61722,0, 61/63, Time: 0.265095s, Loss: 0.273731
30,LA_D_5441528,0,24518,0, 62/63, Time: 0.265095s, Loss: 0.273731
50,LA_D_7974256,0,50504,0, 63/63, Time: 0.265095s, Loss: 0.273731
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
58,LA_T_4928920,0,64000,0, 1/118, Time: 0.506058s, Loss: 0.349694
35,LA_T_3176741,0,62198,0, 2/118, Time: 0.506058s, Loss: 0.349694
12,LA_T_1653822,1,9756,64000, 3/118, Time: 0.506058s, Loss: 0.349694
84,LA_T_6822716,0,27313,0, 4/118, Time: 0.506058s, Loss: 0.349694
36,LA_T_3189628,0,64000,0, 5/118, Time: 0.506058s, Loss: 0.349694
33,LA_T_3021659,0,64000,0, 6/118, Time: 0.506058s, Loss: 0.349694
102,LA_T_7808689,0,64000,0, 7/118, Time: 0.506058s, Loss: 0.349694
74,LA_T_6301739,0,41843,0, 8/118, Time: 0.506058s, Loss: 0.349694
23,LA_T_2320617,0,56846,0, 9/118, Time: 0.506058s, Loss: 0.349694
95,LA_T_7314513,0,39437,0, 10/118, Time: 0.506058s, Loss: 0.349694
56,LA_T_4725126,0,61141,0, 11/118, Time: 0.506058s, Loss: 0.349694
93,LA_T_7281115,0,64000,0, 12/118, Time: 0.506058s, Loss: 0.349694
71,LA_T_5883755,1,19926,64000, 13/118, Time: 0.506058s, Loss: 0.349694
40,LA_T_3319380,0,42032,0, 14/118, Time: 0.506058s, Loss: 0.349694
112,LA_T_9540683,0,25430,0, 15/118, Time: 0.506058s, Loss: 0.349694
82,LA_T_6728875,0,64000,0, 16/118, Time: 0.506058s, Loss: 0.349694
83,LA_T_6751630,0,62290,0, 17/118, Time: 0.506058s, Loss: 0.349694
80,LA_T_6487227,0,44111,0, 18/118, Time: 0.506058s, Loss: 0.349694
52,LA_T_4096754,0,31273,0, 19/118, Time: 0.506058s, Loss: 0.349694
34,LA_T_3021659,1,10227,64000, 20/118, Time: 0.506058s, Loss: 0.349694
28,LA_T_2419035,1,10625,64000, 21/118, Time: 0.506058s, Loss: 0.349694
22,LA_T_2277153,1,21822,64000, 22/118, Time: 0.506058s, Loss: 0.349694
116,LA_T_9746209,1,16967,64000, 23/118, Time: 0.506058s, Loss: 0.349694
8,LA_T_1589546,0,64000,0, 24/118, Time: 0.506058s, Loss: 0.349694
96,LA_T_7359423,0,50164,0, 25/118, Time: 0.506058s, Loss: 0.349694
70,LA_T_5883755,0,64000,0, 26/118, Time: 0.506058s, Loss: 0.349694
48,LA_T_3627265,1,44402,64000, 27/118, Time: 0.506058s, Loss: 0.349694
113,LA_T_9633872,0,27407,0, 28/118, Time: 0.506058s, Loss: 0.349694
103,LA_T_7866363,0,63473,0, 29/118, Time: 0.506058s, Loss: 0.349694
15,LA_T_1870524,0,43190,0, 30/118, Time: 0.506058s, Loss: 0.349694
62,LA_T_5209704,1,34511,64000, 31/118, Time: 0.506058s, Loss: 0.349694
63,LA_T_5214047,0,41920,0, 32/118, Time: 0.506058s, Loss: 0.349694
59,LA_T_5015679,0,41144,0, 33/118, Time: 0.506058s, Loss: 0.349694
68,LA_T_5522733,0,61381,0, 34/118, Time: 0.506058s, Loss: 0.349694
77,LA_T_6390981,0,64000,0, 35/118, Time: 0.506058s, Loss: 0.349694
64,LA_T_5258800,0,54370,0, 36/118, Time: 0.506058s, Loss: 0.349694
27,LA_T_2419035,0,64000,0, 37/118, Time: 0.506058s, Loss: 0.349694
1,LA_T_1258641,0,44562,0, 38/118, Time: 0.506058s, Loss: 0.349694
94,LA_T_7281115,1,11690,64000, 39/118, Time: 0.506058s, Loss: 0.349694
61,LA_T_5209704,0,64000,0, 40/118, Time: 0.506058s, Loss: 0.349694
78,LA_T_6435787,0,43614,0, 41/118, Time: 0.506058s, Loss: 0.349694
29,LA_T_2422854,0,62661,0, 42/118, Time: 0.506058s, Loss: 0.349694
7,LA_T_1518499,0,29284,0, 43/118, Time: 0.506058s, Loss: 0.349694
109,LA_T_8527420,0,63377,0, 44/118, Time: 0.506058s, Loss: 0.349694
31,LA_T_2677562,0,63649,0, 45/118, Time: 0.506058s, Loss: 0.349694
53,LA_T_4512109,0,51563,0, 46/118, Time: 0.506058s, Loss: 0.349694
30,LA_T_2584761,0,47107,0, 47/118, Time: 0.506058s, Loss: 0.349694
2,LA_T_1346935,0,45741,0, 48/118, Time: 0.506058s, Loss: 0.349694
51,LA_T_3993688,0,48709,0, 49/118, Time: 0.506058s, Loss: 0.349694
106,LA_T_8090857,0,64000,0, 50/118, Time: 0.506058s, Loss: 0.349694
13,LA_T_1724943,0,60906,0, 51/118, Time: 0.506058s, Loss: 0.349694
32,LA_T_2995069,0,49112,0, 52/118, Time: 0.506058s, Loss: 0.349694
0,LA_T_1154440,0,30107,0, 53/118, Time: 0.506058s, Loss: 0.349694
69,LA_T_5786445,0,64000,0, 54/118, Time: 0.506058s, Loss: 0.349694
9,LA_T_1589546,1,9736,64000, 55/118, Time: 0.506058s, Loss: 0.349694
20,LA_T_2269038,0,63442,0, 56/118, Time: 0.506058s, Loss: 0.349694
98,LA_T_7422011,0,45646,0, 57/118, Time: 0.506058s, Loss: 0.349694
92,LA_T_7273305,0,53173,0, 58/118, Time: 0.506058s, Loss: 0.349694
108,LA_T_8234484,0,46183,0, 59/118, Time: 0.506058s, Loss: 0.349694
5,LA_T_1486451,0,50406,0, 60/118, Time: 0.506058s, Loss: 0.349694
3,LA_T_1373588,0,46949,0, 61/118, Time: 0.506058s, Loss: 0.349694
65,LA_T_5360018,0,54554,0, 62/118, Time: 0.506058s, Loss: 0.349694
89,LA_T_7124444,0,64000,0, 63/118, Time: 0.506058s, Loss: 0.349694
24,LA_T_2327393,0,60701,0, 64/118, Time: 0.506058s, Loss: 0.349694
50,LA_T_3935691,0,39156,0, 65/118, Time: 0.548278s, Loss: 0.298191
26,LA_T_2354581,0,47687,0, 66/118, Time: 0.548278s, Loss: 0.298191
101,LA_T_7706110,0,24083,0, 67/118, Time: 0.548278s, Loss: 0.298191
17,LA_T_1909651,1,64000,64000, 68/118, Time: 0.548278s, Loss: 0.298191
79,LA_T_6476207,0,54948,0, 69/118, Time: 0.548278s, Loss: 0.298191
110,LA_T_8681550,0,40836,0, 70/118, Time: 0.548278s, Loss: 0.298191
88,LA_T_7020532,0,59863,0, 71/118, Time: 0.548278s, Loss: 0.298191
47,LA_T_3627265,0,64000,0, 72/118, Time: 0.548278s, Loss: 0.298191
21,LA_T_2277153,0,64000,0, 73/118, Time: 0.548278s, Loss: 0.298191
66,LA_T_5433188,0,34172,0, 74/118, Time: 0.548278s, Loss: 0.298191
104,LA_T_7888797,0,26626,0, 75/118, Time: 0.548278s, Loss: 0.298191
55,LA_T_4630359,0,64000,0, 76/118, Time: 0.548278s, Loss: 0.298191
73,LA_T_5978739,0,33363,0, 77/118, Time: 0.548278s, Loss: 0.298191
39,LA_T_3250806,0,61271,0, 78/118, Time: 0.548278s, Loss: 0.298191
87,LA_T_6960076,0,42296,0, 79/118, Time: 0.548278s, Loss: 0.298191
105,LA_T_8007992,0,45465,0, 80/118, Time: 0.548278s, Loss: 0.298191
41,LA_T_3391018,0,57402,0, 81/118, Time: 0.548278s, Loss: 0.298191
4,LA_T_1470918,0,39641,0, 82/118, Time: 0.548278s, Loss: 0.298191
45,LA_T_3527643,1,8295,64000, 83/118, Time: 0.548278s, Loss: 0.298191
76,LA_T_6331069,1,64000,64000, 84/118, Time: 0.548278s, Loss: 0.298191
57,LA_T_4774044,0,59379,0, 85/118, Time: 0.548278s, Loss: 0.298191
43,LA_T_3467377,1,26131,64000, 86/118, Time: 0.548278s, Loss: 0.298191
25,LA_T_2333843,0,61708,0, 87/118, Time: 0.548278s, Loss: 0.298191
81,LA_T_6521388,0,64000,0, 88/118, Time: 0.548278s, Loss: 0.298191
10,LA_T_1630611,0,58109,0, 89/118, Time: 0.548278s, Loss: 0.298191
42,LA_T_3467377,0,64000,0, 90/118, Time: 0.548278s, Loss: 0.298191
100,LA_T_7550620,0,44981,0, 91/118, Time: 0.548278s, Loss: 0.298191
86,LA_T_6941395,1,29307,64000, 92/118, Time: 0.548278s, Loss: 0.298191
75,LA_T_6331069,0,64000,0, 93/118, Time: 0.548278s, Loss: 0.298191
60,LA_T_5205025,0,61550,0, 94/118, Time: 0.548278s, Loss: 0.298191
14,LA_T_1836557,0,43646,0, 95/118, Time: 0.548278s, Loss: 0.298191
90,LA_T_7124444,1,21405,64000, 96/118, Time: 0.548278s, Loss: 0.298191
114,LA_T_9668514,0,54564,0, 97/118, Time: 0.548278s, Loss: 0.298191
46,LA_T_3588714,0,46298,0, 98/118, Time: 0.548278s, Loss: 0.298191
99,LA_T_7529623,0,43309,0, 99/118, Time: 0.548278s, Loss: 0.298191
115,LA_T_9746209,0,64000,0, 100/118, Time: 0.548278s, Loss: 0.298191
38,LA_T_3220265,0,38149,0, 101/118, Time: 0.548278s, Loss: 0.298191
49,LA_T_3758169,0,46047,0, 102/118, Time: 0.548278s, Loss: 0.298191
85,LA_T_6941395,0,64000,0, 103/118, Time: 0.548278s, Loss: 0.298191
37,LA_T_3189628,1,15851,64000, 104/118, Time: 0.548278s, Loss: 0.298191
44,LA_T_3527643,0,64000,0, 105/118, Time: 0.548278s, Loss: 0.298191
11,LA_T_1653822,0,64000,0, 106/118, Time: 0.548278s, Loss: 0.298191
18,LA_T_1909651,2,24481,128000, 107/118, Time: 0.548278s, Loss: 0.298191
6,LA_T_1490244,0,55572,0, 108/118, Time: 0.548278s, Loss: 0.298191
97,LA_T_7405543,0,36914,0, 109/118, Time: 0.548278s, Loss: 0.298191
111,LA_T_9226984,0,45529,0, 110/118, Time: 0.548278s, Loss: 0.298191
72,LA_T_5894355,0,64000,0, 111/118, Time: 0.548278s, Loss: 0.298191
19,LA_T_2052267,0,38415,0, 112/118, Time: 0.548278s, Loss: 0.298191
107,LA_T_8206162,0,55328,0, 113/118, Time: 0.548278s, Loss: 0.298191
117,LA_T_9830298,0,64000,0, 114/118, Time: 0.548278s, Loss: 0.298191
54,LA_T_4584407,0,36921,0, 115/118, Time: 0.548278s, Loss: 0.298191
91,LA_T_7223887,0,40210,0, 116/118, Time: 0.548278s, Loss: 0.298191
16,LA_T_1909651,0,64000,0, 117/118, Time: 0.548278s, Loss: 0.298191
67,LA_T_5492534,0,28365,0, 118/118, Time: 0.548278s, Loss: 0.298191
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
25,LA_D_4630224,0,27639,0, 1/63, Time: 0.252675s, Loss: 0.266219
62,LA_D_9753761,1,22997,64000, 2/63, Time: 0.252675s, Loss: 0.266219
23,LA_D_4519635,0,64000,0, 3/63, Time: 0.252675s, Loss: 0.266219
24,LA_D_4519635,1,12487,64000, 4/63, Time: 0.252675s, Loss: 0.266219
7,LA_D_1803008,0,45707,0, 5/63, Time: 0.252675s, Loss: 0.266219
21,LA_D_4276413,0,49755,0, 6/63, Time: 0.252675s, Loss: 0.266219
11,LA_D_2648941,1,41414,64000, 7/63, Time: 0.252675s, Loss: 0.266219
41,LA_D_6180779,0,23109,0, 8/63, Time: 0.252675s, Loss: 0.266219
29,LA_D_5300881,1,27489,64000, 9/63, Time: 0.252675s, Loss: 0.266219
26,LA_D_5239066,0,64000,0, 10/63, Time: 0.252675s, Loss: 0.266219
48,LA_D_7869978,1,20551,64000, 11/63, Time: 0.252675s, Loss: 0.266219
36,LA_D_5835948,1,29523,64000, 12/63, Time: 0.252675s, Loss: 0.266219
51,LA_D_8228250,0,42344,0, 13/63, Time: 0.252675s, Loss: 0.266219
9,LA_D_2082512,0,53318,0, 14/63, Time: 0.252675s, Loss: 0.266219
27,LA_D_5239066,1,30014,64000, 15/63, Time: 0.252675s, Loss: 0.266219
44,LA_D_7095518,0,56482,0, 16/63, Time: 0.252675s, Loss: 0.266219
59,LA_D_9686838,0,64000,0, 17/63, Time: 0.252675s, Loss: 0.266219
58,LA_D_9566347,0,35349,0, 18/63, Time: 0.252675s, Loss: 0.266219
15,LA_D_3203408,0,49607,0, 19/63, Time: 0.252675s, Loss: 0.266219
52,LA_D_8284460,0,50174,0, 20/63, Time: 0.252675s, Loss: 0.266219
30,LA_D_5441528,0,24518,0, 21/63, Time: 0.252675s, Loss: 0.266219
43,LA_D_7026375,0,61915,0, 22/63, Time: 0.252675s, Loss: 0.266219
61,LA_D_9753761,0,64000,0, 23/63, Time: 0.252675s, Loss: 0.266219
50,LA_D_7974256,0,50504,0, 24/63, Time: 0.252675s, Loss: 0.266219
32,LA_D_5505879,1,35600,64000, 25/63, Time: 0.252675s, Loss: 0.266219
49,LA_D_7933136,0,64000,0, 26/63, Time: 0.252675s, Loss: 0.266219
45,LA_D_7452217,0,25016,0, 27/63, Time: 0.252675s, Loss: 0.266219
38,LA_D_5944972,0,64000,0, 28/63, Time: 0.252675s, Loss: 0.266219
8,LA_D_1886178,0,40092,0, 29/63, Time: 0.252675s, Loss: 0.266219
19,LA_D_4013191,0,34443,0, 30/63, Time: 0.252675s, Loss: 0.266219
0,LA_D_1179848,0,64000,0, 31/63, Time: 0.252675s, Loss: 0.266219
4,LA_D_1366945,0,45986,0, 32/63, Time: 0.252675s, Loss: 0.266219
13,LA_D_2949136,0,64000,0, 33/63, Time: 0.252675s, Loss: 0.266219
3,LA_D_1317561,1,8976,64000, 34/63, Time: 0.252675s, Loss: 0.266219
10,LA_D_2648941,0,64000,0, 35/63, Time: 0.252675s, Loss: 0.266219
22,LA_D_4394367,0,61722,0, 36/63, Time: 0.252675s, Loss: 0.266219
33,LA_D_5659407,0,64000,0, 37/63, Time: 0.252675s, Loss: 0.266219
34,LA_D_5741681,0,44990,0, 38/63, Time: 0.252675s, Loss: 0.266219
20,LA_D_4265541,0,26061,0, 39/63, Time: 0.252675s, Loss: 0.266219
54,LA_D_8998984,0,37498,0, 40/63, Time: 0.252675s, Loss: 0.266219
1,LA_D_1179848,1,29541,64000, 41/63, Time: 0.252675s, Loss: 0.266219
16,LA_D_3457616,0,51111,0, 42/63, Time: 0.252675s, Loss: 0.266219
31,LA_D_5505879,0,64000,0, 43/63, Time: 0.252675s, Loss: 0.266219
14,LA_D_2949136,1,27301,64000, 44/63, Time: 0.252675s, Loss: 0.266219
53,LA_D_8584336,0,61424,0, 45/63, Time: 0.252675s, Loss: 0.266219
37,LA_D_5891869,0,54006,0, 46/63, Time: 0.252675s, Loss: 0.266219
6,LA_D_1580841,0,38838,0, 47/63, Time: 0.252675s, Loss: 0.266219
2,LA_D_1317561,0,64000,0, 48/63, Time: 0.252675s, Loss: 0.266219
60,LA_D_9686838,1,28544,64000, 49/63, Time: 0.252675s, Loss: 0.266219
12,LA_D_2896709,0,64000,0, 50/63, Time: 0.252675s, Loss: 0.266219
55,LA_D_9192205,0,40612,0, 51/63, Time: 0.252675s, Loss: 0.266219
46,LA_D_7862876,0,57311,0, 52/63, Time: 0.252675s, Loss: 0.266219
28,LA_D_5300881,0,64000,0, 53/63, Time: 0.252675s, Loss: 0.266219
39,LA_D_5944972,1,39788,64000, 54/63, Time: 0.252675s, Loss: 0.266219
42,LA_D_6502788,0,29166,0, 55/63, Time: 0.252675s, Loss: 0.266219
40,LA_D_6055606,0,53176,0, 56/63, Time: 0.252675s, Loss: 0.266219
18,LA_D_3983088,0,21649,0, 57/63, Time: 0.252675s, Loss: 0.266219
47,LA_D_7869978,0,64000,0, 58/63, Time: 0.252675s, Loss: 0.266219
5,LA_D_1435765,0,47544,0, 59/63, Time: 0.252675s, Loss: 0.266219
56,LA_D_9316963,0,58699,0, 60/63, Time: 0.252675s, Loss: 0.266219
57,LA_D_9493396,0,40904,0, 61/63, Time: 0.252675s, Loss: 0.266219
17,LA_D_3705418,0,64000,0, 62/63, Time: 0.252675s, Loss: 0.266219
35,LA_D_5835948,0,64000,0, 63/63, Time: 0.252675s, Loss: 0.266219
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
83,LA_T_6751630,0,62290,0, 1/118, Time: 0.493396s, Loss: 0.222289
114,LA_T_9668514,0,54564,0, 2/118, Time: 0.493396s, Loss: 0.222289
117,LA_T_9830298,0,64000,0, 3/118, Time: 0.493396s, Loss: 0.222289
48,LA_T_3627265,1,44402,64000, 4/118, Time: 0.493396s, Loss: 0.222289
19,LA_T_2052267,0,38415,0, 5/118, Time: 0.493396s, Loss: 0.222289
33,LA_T_3021659,0,64000,0, 6/118, Time: 0.493396s, Loss: 0.222289
79,LA_T_6476207,0,54948,0, 7/118, Time: 0.493396s, Loss: 0.222289
98,LA_T_7422011,0,45646,0, 8/118, Time: 0.493396s, Loss: 0.222289
72,LA_T_5894355,0,64000,0, 9/118, Time: 0.493396s, Loss: 0.222289
23,LA_T_2320617,0,56846,0, 10/118, Time: 0.493396s, Loss: 0.222289
46,LA_T_3588714,0,46298,0, 11/118, Time: 0.493396s, Loss: 0.222289
8,LA_T_1589546,0,64000,0, 12/118, Time: 0.493396s, Loss: 0.222289
84,LA_T_6822716,0,27313,0, 13/118, Time: 0.493396s, Loss: 0.222289
5,LA_T_1486451,0,50406,0, 14/118, Time: 0.493396s, Loss: 0.222289
108,LA_T_8234484,0,46183,0, 15/118, Time: 0.493396s, Loss: 0.222289
75,LA_T_6331069,0,64000,0, 16/118, Time: 0.493396s, Loss: 0.222289
58,LA_T_4928920,0,64000,0, 17/118, Time: 0.493396s, Loss: 0.222289
16,LA_T_1909651,0,64000,0, 18/118, Time: 0.493396s, Loss: 0.222289
107,LA_T_8206162,0,55328,0, 19/118, Time: 0.493396s, Loss: 0.222289
50,LA_T_3935691,0,39156,0, 20/118, Time: 0.493396s, Loss: 0.222289
26,LA_T_2354581,0,47687,0, 21/118, Time: 0.493396s, Loss: 0.222289
80,LA_T_6487227,0,44111,0, 22/118, Time: 0.493396s, Loss: 0.222289
88,LA_T_7020532,0,59863,0, 23/118, Time: 0.493396s, Loss: 0.222289
63,LA_T_5214047,0,41920,0, 24/118, Time: 0.493396s, Loss: 0.222289
31,LA_T_2677562,0,63649,0, 25/118, Time: 0.493396s, Loss: 0.222289
52,LA_T_4096754,0,31273,0, 26/118, Time: 0.493396s, Loss: 0.222289
11,LA_T_1653822,0,64000,0, 27/118, Time: 0.493396s, Loss: 0.222289
6,LA_T_1490244,0,55572,0, 28/118, Time: 0.493396s, Loss: 0.222289
97,LA_T_7405543,0,36914,0, 29/118, Time: 0.493396s, Loss: 0.222289
89,LA_T_7124444,0,64000,0, 30/118, Time: 0.493396s, Loss: 0.222289
25,LA_T_2333843,0,61708,0, 31/118, Time: 0.493396s, Loss: 0.222289
43,LA_T_3467377,1,26131,64000, 32/118, Time: 0.493396s, Loss: 0.222289
7,LA_T_1518499,0,29284,0, 33/118, Time: 0.493396s, Loss: 0.222289
42,LA_T_3467377,0,64000,0, 34/118, Time: 0.493396s, Loss: 0.222289
68,LA_T_5522733,0,61381,0, 35/118, Time: 0.493396s, Loss: 0.222289
51,LA_T_3993688,0,48709,0, 36/118, Time: 0.493396s, Loss: 0.222289
35,LA_T_3176741,0,62198,0, 37/118, Time: 0.493396s, Loss: 0.222289
102,LA_T_7808689,0,64000,0, 38/118, Time: 0.493396s, Loss: 0.222289
85,LA_T_6941395,0,64000,0, 39/118, Time: 0.493396s, Loss: 0.222289
67,LA_T_5492534,0,28365,0, 40/118, Time: 0.493396s, Loss: 0.222289
38,LA_T_3220265,0,38149,0, 41/118, Time: 0.493396s, Loss: 0.222289
36,LA_T_3189628,0,64000,0, 42/118, Time: 0.493396s, Loss: 0.222289
20,LA_T_2269038,0,63442,0, 43/118, Time: 0.493396s, Loss: 0.222289
56,LA_T_4725126,0,61141,0, 44/118, Time: 0.493396s, Loss: 0.222289
65,LA_T_5360018,0,54554,0, 45/118, Time: 0.493396s, Loss: 0.222289
70,LA_T_5883755,0,64000,0, 46/118, Time: 0.493396s, Loss: 0.222289
101,LA_T_7706110,0,24083,0, 47/118, Time: 0.493396s, Loss: 0.222289
34,LA_T_3021659,1,10227,64000, 48/118, Time: 0.493396s, Loss: 0.222289
95,LA_T_7314513,0,39437,0, 49/118, Time: 0.493396s, Loss: 0.222289
87,LA_T_6960076,0,42296,0, 50/118, Time: 0.493396s, Loss: 0.222289
41,LA_T_3391018,0,57402,0, 51/118, Time: 0.493396s, Loss: 0.222289
105,LA_T_8007992,0,45465,0, 52/118, Time: 0.493396s, Loss: 0.222289
104,LA_T_7888797,0,26626,0, 53/118, Time: 0.493396s, Loss: 0.222289
64,LA_T_5258800,0,54370,0, 54/118, Time: 0.493396s, Loss: 0.222289
9,LA_T_1589546,1,9736,64000, 55/118, Time: 0.493396s, Loss: 0.222289
24,LA_T_2327393,0,60701,0, 56/118, Time: 0.493396s, Loss: 0.222289
116,LA_T_9746209,1,16967,64000, 57/118, Time: 0.493396s, Loss: 0.222289
1,LA_T_1258641,0,44562,0, 58/118, Time: 0.493396s, Loss: 0.222289
49,LA_T_3758169,0,46047,0, 59/118, Time: 0.493396s, Loss: 0.222289
71,LA_T_5883755,1,19926,64000, 60/118, Time: 0.493396s, Loss: 0.222289
94,LA_T_7281115,1,11690,64000, 61/118, Time: 0.493396s, Loss: 0.222289
2,LA_T_1346935,0,45741,0, 62/118, Time: 0.493396s, Loss: 0.222289
96,LA_T_7359423,0,50164,0, 63/118, Time: 0.493396s, Loss: 0.222289
22,LA_T_2277153,1,21822,64000, 64/118, Time: 0.493396s, Loss: 0.222289
106,LA_T_8090857,0,64000,0, 65/118, Time: 0.548222s, Loss: 0.452376
40,LA_T_3319380,0,42032,0, 66/118, Time: 0.548222s, Loss: 0.452376
76,LA_T_6331069,1,64000,64000, 67/118, Time: 0.548222s, Loss: 0.452376
69,LA_T_5786445,0,64000,0, 68/118, Time: 0.548222s, Loss: 0.452376
115,LA_T_9746209,0,64000,0, 69/118, Time: 0.548222s, Loss: 0.452376
112,LA_T_9540683,0,25430,0, 70/118, Time: 0.548222s, Loss: 0.452376
90,LA_T_7124444,1,21405,64000, 71/118, Time: 0.548222s, Loss: 0.452376
3,LA_T_1373588,0,46949,0, 72/118, Time: 0.548222s, Loss: 0.452376
29,LA_T_2422854,0,62661,0, 73/118, Time: 0.548222s, Loss: 0.452376
17,LA_T_1909651,1,64000,64000, 74/118, Time: 0.548222s, Loss: 0.452376
60,LA_T_5205025,0,61550,0, 75/118, Time: 0.548222s, Loss: 0.452376
15,LA_T_1870524,0,43190,0, 76/118, Time: 0.548222s, Loss: 0.452376
92,LA_T_7273305,0,53173,0, 77/118, Time: 0.548222s, Loss: 0.452376
30,LA_T_2584761,0,47107,0, 78/118, Time: 0.548222s, Loss: 0.452376
109,LA_T_8527420,0,63377,0, 79/118, Time: 0.548222s, Loss: 0.452376
61,LA_T_5209704,0,64000,0, 80/118, Time: 0.548222s, Loss: 0.452376
39,LA_T_3250806,0,61271,0, 81/118, Time: 0.548222s, Loss: 0.452376
0,LA_T_1154440,0,30107,0, 82/118, Time: 0.548222s, Loss: 0.452376
113,LA_T_9633872,0,27407,0, 83/118, Time: 0.548222s, Loss: 0.452376
78,LA_T_6435787,0,43614,0, 84/118, Time: 0.548222s, Loss: 0.452376
18,LA_T_1909651,2,24481,128000, 85/118, Time: 0.548222s, Loss: 0.452376
4,LA_T_1470918,0,39641,0, 86/118, Time: 0.548222s, Loss: 0.452376
45,LA_T_3527643,1,8295,64000, 87/118, Time: 0.548222s, Loss: 0.452376
73,LA_T_5978739,0,33363,0, 88/118, Time: 0.548222s, Loss: 0.452376
86,LA_T_6941395,1,29307,64000, 89/118, Time: 0.548222s, Loss: 0.452376
57,LA_T_4774044,0,59379,0, 90/118, Time: 0.548222s, Loss: 0.452376
14,LA_T_1836557,0,43646,0, 91/118, Time: 0.548222s, Loss: 0.452376
111,LA_T_9226984,0,45529,0, 92/118, Time: 0.548222s, Loss: 0.452376
100,LA_T_7550620,0,44981,0, 93/118, Time: 0.548222s, Loss: 0.452376
54,LA_T_4584407,0,36921,0, 94/118, Time: 0.548222s, Loss: 0.452376
110,LA_T_8681550,0,40836,0, 95/118, Time: 0.548222s, Loss: 0.452376
59,LA_T_5015679,0,41144,0, 96/118, Time: 0.548222s, Loss: 0.452376
82,LA_T_6728875,0,64000,0, 97/118, Time: 0.548222s, Loss: 0.452376
62,LA_T_5209704,1,34511,64000, 98/118, Time: 0.548222s, Loss: 0.452376
103,LA_T_7866363,0,63473,0, 99/118, Time: 0.548222s, Loss: 0.452376
47,LA_T_3627265,0,64000,0, 100/118, Time: 0.548222s, Loss: 0.452376
81,LA_T_6521388,0,64000,0, 101/118, Time: 0.548222s, Loss: 0.452376
55,LA_T_4630359,0,64000,0, 102/118, Time: 0.548222s, Loss: 0.452376
44,LA_T_3527643,0,64000,0, 103/118, Time: 0.548222s, Loss: 0.452376
91,LA_T_7223887,0,40210,0, 104/118, Time: 0.548222s, Loss: 0.452376
12,LA_T_1653822,1,9756,64000, 105/118, Time: 0.548222s, Loss: 0.452376
99,LA_T_7529623,0,43309,0, 106/118, Time: 0.548222s, Loss: 0.452376
74,LA_T_6301739,0,41843,0, 107/118, Time: 0.548222s, Loss: 0.452376
28,LA_T_2419035,1,10625,64000, 108/118, Time: 0.548222s, Loss: 0.452376
37,LA_T_3189628,1,15851,64000, 109/118, Time: 0.548222s, Loss: 0.452376
32,LA_T_2995069,0,49112,0, 110/118, Time: 0.548222s, Loss: 0.452376
77,LA_T_6390981,0,64000,0, 111/118, Time: 0.548222s, Loss: 0.452376
10,LA_T_1630611,0,58109,0, 112/118, Time: 0.548222s, Loss: 0.452376
13,LA_T_1724943,0,60906,0, 113/118, Time: 0.548222s, Loss: 0.452376
66,LA_T_5433188,0,34172,0, 114/118, Time: 0.548222s, Loss: 0.452376
21,LA_T_2277153,0,64000,0, 115/118, Time: 0.548222s, Loss: 0.452376
53,LA_T_4512109,0,51563,0, 116/118, Time: 0.548222s, Loss: 0.452376
93,LA_T_7281115,0,64000,0, 117/118, Time: 0.548222s, Loss: 0.452376
27,LA_T_2419035,0,64000,0, 118/118, Time: 0.548222s, Loss: 0.452376
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
61,LA_D_9753761,0,64000,0, 1/63, Time: 0.256001s, Loss: 0.286485
26,LA_D_5239066,0,64000,0, 2/63, Time: 0.256001s, Loss: 0.286485
43,LA_D_7026375,0,61915,0, 3/63, Time: 0.256001s, Loss: 0.286485
56,LA_D_9316963,0,58699,0, 4/63, Time: 0.256001s, Loss: 0.286485
29,LA_D_5300881,1,27489,64000, 5/63, Time: 0.256001s, Loss: 0.286485
49,LA_D_7933136,0,64000,0, 6/63, Time: 0.256001s, Loss: 0.286485
40,LA_D_6055606,0,53176,0, 7/63, Time: 0.256001s, Loss: 0.286485
23,LA_D_4519635,0,64000,0, 8/63, Time: 0.256001s, Loss: 0.286485
35,LA_D_5835948,0,64000,0, 9/63, Time: 0.256001s, Loss: 0.286485
28,LA_D_5300881,0,64000,0, 10/63, Time: 0.256001s, Loss: 0.286485
15,LA_D_3203408,0,49607,0, 11/63, Time: 0.256001s, Loss: 0.286485
16,LA_D_3457616,0,51111,0, 12/63, Time: 0.256001s, Loss: 0.286485
20,LA_D_4265541,0,26061,0, 13/63, Time: 0.256001s, Loss: 0.286485
45,LA_D_7452217,0,25016,0, 14/63, Time: 0.256001s, Loss: 0.286485
18,LA_D_3983088,0,21649,0, 15/63, Time: 0.256001s, Loss: 0.286485
39,LA_D_5944972,1,39788,64000, 16/63, Time: 0.256001s, Loss: 0.286485
52,LA_D_8284460,0,50174,0, 17/63, Time: 0.256001s, Loss: 0.286485
42,LA_D_6502788,0,29166,0, 18/63, Time: 0.256001s, Loss: 0.286485
41,LA_D_6180779,0,23109,0, 19/63, Time: 0.256001s, Loss: 0.286485
53,LA_D_8584336,0,61424,0, 20/63, Time: 0.256001s, Loss: 0.286485
21,LA_D_4276413,0,49755,0, 21/63, Time: 0.256001s, Loss: 0.286485
34,LA_D_5741681,0,44990,0, 22/63, Time: 0.256001s, Loss: 0.286485
17,LA_D_3705418,0,64000,0, 23/63, Time: 0.256001s, Loss: 0.286485
8,LA_D_1886178,0,40092,0, 24/63, Time: 0.256001s, Loss: 0.286485
14,LA_D_2949136,1,27301,64000, 25/63, Time: 0.256001s, Loss: 0.286485
22,LA_D_4394367,0,61722,0, 26/63, Time: 0.256001s, Loss: 0.286485
4,LA_D_1366945,0,45986,0, 27/63, Time: 0.256001s, Loss: 0.286485
0,LA_D_1179848,0,64000,0, 28/63, Time: 0.256001s, Loss: 0.286485
60,LA_D_9686838,1,28544,64000, 29/63, Time: 0.256001s, Loss: 0.286485
46,LA_D_7862876,0,57311,0, 30/63, Time: 0.256001s, Loss: 0.286485
47,LA_D_7869978,0,64000,0, 31/63, Time: 0.256001s, Loss: 0.286485
50,LA_D_7974256,0,50504,0, 32/63, Time: 0.256001s, Loss: 0.286485
11,LA_D_2648941,1,41414,64000, 33/63, Time: 0.256001s, Loss: 0.286485
6,LA_D_1580841,0,38838,0, 34/63, Time: 0.256001s, Loss: 0.286485
19,LA_D_4013191,0,34443,0, 35/63, Time: 0.256001s, Loss: 0.286485
12,LA_D_2896709,0,64000,0, 36/63, Time: 0.256001s, Loss: 0.286485
59,LA_D_9686838,0,64000,0, 37/63, Time: 0.256001s, Loss: 0.286485
54,LA_D_8998984,0,37498,0, 38/63, Time: 0.256001s, Loss: 0.286485
5,LA_D_1435765,0,47544,0, 39/63, Time: 0.256001s, Loss: 0.286485
7,LA_D_1803008,0,45707,0, 40/63, Time: 0.256001s, Loss: 0.286485
10,LA_D_2648941,0,64000,0, 41/63, Time: 0.256001s, Loss: 0.286485
13,LA_D_2949136,0,64000,0, 42/63, Time: 0.256001s, Loss: 0.286485
51,LA_D_8228250,0,42344,0, 43/63, Time: 0.256001s, Loss: 0.286485
30,LA_D_5441528,0,24518,0, 44/63, Time: 0.256001s, Loss: 0.286485
27,LA_D_5239066,1,30014,64000, 45/63, Time: 0.256001s, Loss: 0.286485
58,LA_D_9566347,0,35349,0, 46/63, Time: 0.256001s, Loss: 0.286485
1,LA_D_1179848,1,29541,64000, 47/63, Time: 0.256001s, Loss: 0.286485
24,LA_D_4519635,1,12487,64000, 48/63, Time: 0.256001s, Loss: 0.286485
25,LA_D_4630224,0,27639,0, 49/63, Time: 0.256001s, Loss: 0.286485
48,LA_D_7869978,1,20551,64000, 50/63, Time: 0.256001s, Loss: 0.286485
33,LA_D_5659407,0,64000,0, 51/63, Time: 0.256001s, Loss: 0.286485
57,LA_D_9493396,0,40904,0, 52/63, Time: 0.256001s, Loss: 0.286485
32,LA_D_5505879,1,35600,64000, 53/63, Time: 0.256001s, Loss: 0.286485
9,LA_D_2082512,0,53318,0, 54/63, Time: 0.256001s, Loss: 0.286485
38,LA_D_5944972,0,64000,0, 55/63, Time: 0.256001s, Loss: 0.286485
55,LA_D_9192205,0,40612,0, 56/63, Time: 0.256001s, Loss: 0.286485
62,LA_D_9753761,1,22997,64000, 57/63, Time: 0.256001s, Loss: 0.286485
3,LA_D_1317561,1,8976,64000, 58/63, Time: 0.256001s, Loss: 0.286485
31,LA_D_5505879,0,64000,0, 59/63, Time: 0.256001s, Loss: 0.286485
37,LA_D_5891869,0,54006,0, 60/63, Time: 0.256001s, Loss: 0.286485
44,LA_D_7095518,0,56482,0, 61/63, Time: 0.256001s, Loss: 0.286485
2,LA_D_1317561,0,64000,0, 62/63, Time: 0.256001s, Loss: 0.286485
36,LA_D_5835948,1,29523,64000, 63/63, Time: 0.256001s, Loss: 0.286485
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
100,LA_T_7550620,0,44981,0, 1/118, Time: 0.511773s, Loss: 0.338221
62,LA_T_5209704,1,34511,64000, 2/118, Time: 0.511773s, Loss: 0.338221
117,LA_T_9830298,0,64000,0, 3/118, Time: 0.511773s, Loss: 0.338221
35,LA_T_3176741,0,62198,0, 4/118, Time: 0.511773s, Loss: 0.338221
30,LA_T_2584761,0,47107,0, 5/118, Time: 0.511773s, Loss: 0.338221
114,LA_T_9668514,0,54564,0, 6/118, Time: 0.511773s, Loss: 0.338221
47,LA_T_3627265,0,64000,0, 7/118, Time: 0.511773s, Loss: 0.338221
32,LA_T_2995069,0,49112,0, 8/118, Time: 0.511773s, Loss: 0.338221
107,LA_T_8206162,0,55328,0, 9/118, Time: 0.511773s, Loss: 0.338221
29,LA_T_2422854,0,62661,0, 10/118, Time: 0.511773s, Loss: 0.338221
43,LA_T_3467377,1,26131,64000, 11/118, Time: 0.511773s, Loss: 0.338221
105,LA_T_8007992,0,45465,0, 12/118, Time: 0.511773s, Loss: 0.338221
22,LA_T_2277153,1,21822,64000, 13/118, Time: 0.511773s, Loss: 0.338221
74,LA_T_6301739,0,41843,0, 14/118, Time: 0.511773s, Loss: 0.338221
97,LA_T_7405543,0,36914,0, 15/118, Time: 0.511773s, Loss: 0.338221
67,LA_T_5492534,0,28365,0, 16/118, Time: 0.511773s, Loss: 0.338221
69,LA_T_5786445,0,64000,0, 17/118, Time: 0.511773s, Loss: 0.338221
112,LA_T_9540683,0,25430,0, 18/118, Time: 0.511773s, Loss: 0.338221
3,LA_T_1373588,0,46949,0, 19/118, Time: 0.511773s, Loss: 0.338221
83,LA_T_6751630,0,62290,0, 20/118, Time: 0.511773s, Loss: 0.338221
20,LA_T_2269038,0,63442,0, 21/118, Time: 0.511773s, Loss: 0.338221
38,LA_T_3220265,0,38149,0, 22/118, Time: 0.511773s, Loss: 0.338221
42,LA_T_3467377,0,64000,0, 23/118, Time: 0.511773s, Loss: 0.338221
7,LA_T_1518499,0,29284,0, 24/118, Time: 0.511773s, Loss: 0.338221
19,LA_T_2052267,0,38415,0, 25/118, Time: 0.511773s, Loss: 0.338221
111,LA_T_9226984,0,45529,0, 26/118, Time: 0.511773s, Loss: 0.338221
49,LA_T_3758169,0,46047,0, 27/118, Time: 0.511773s, Loss: 0.338221
53,LA_T_4512109,0,51563,0, 28/118, Time: 0.511773s, Loss: 0.338221
102,LA_T_7808689,0,64000,0, 29/118, Time: 0.511773s, Loss: 0.338221
90,LA_T_7124444,1,21405,64000, 30/118, Time: 0.511773s, Loss: 0.338221
110,LA_T_8681550,0,40836,0, 31/118, Time: 0.511773s, Loss: 0.338221
24,LA_T_2327393,0,60701,0, 32/118, Time: 0.511773s, Loss: 0.338221
93,LA_T_7281115,0,64000,0, 33/118, Time: 0.511773s, Loss: 0.338221
51,LA_T_3993688,0,48709,0, 34/118, Time: 0.511773s, Loss: 0.338221
23,LA_T_2320617,0,56846,0, 35/118, Time: 0.511773s, Loss: 0.338221
108,LA_T_8234484,0,46183,0, 36/118, Time: 0.511773s, Loss: 0.338221
9,LA_T_1589546,1,9736,64000, 37/118, Time: 0.511773s, Loss: 0.338221
58,LA_T_4928920,0,64000,0, 38/118, Time: 0.511773s, Loss: 0.338221
13,LA_T_1724943,0,60906,0, 39/118, Time: 0.511773s, Loss: 0.338221
4,LA_T_1470918,0,39641,0, 40/118, Time: 0.511773s, Loss: 0.338221
11,LA_T_1653822,0,64000,0, 41/118, Time: 0.511773s, Loss: 0.338221
98,LA_T_7422011,0,45646,0, 42/118, Time: 0.511773s, Loss: 0.338221
71,LA_T_5883755,1,19926,64000, 43/118, Time: 0.511773s, Loss: 0.338221
54,LA_T_4584407,0,36921,0, 44/118, Time: 0.511773s, Loss: 0.338221
55,LA_T_4630359,0,64000,0, 45/118, Time: 0.511773s, Loss: 0.338221
25,LA_T_2333843,0,61708,0, 46/118, Time: 0.511773s, Loss: 0.338221
85,LA_T_6941395,0,64000,0, 47/118, Time: 0.511773s, Loss: 0.338221
1,LA_T_1258641,0,44562,0, 48/118, Time: 0.511773s, Loss: 0.338221
78,LA_T_6435787,0,43614,0, 49/118, Time: 0.511773s, Loss: 0.338221
44,LA_T_3527643,0,64000,0, 50/118, Time: 0.511773s, Loss: 0.338221
115,LA_T_9746209,0,64000,0, 51/118, Time: 0.511773s, Loss: 0.338221
72,LA_T_5894355,0,64000,0, 52/118, Time: 0.511773s, Loss: 0.338221
76,LA_T_6331069,1,64000,64000, 53/118, Time: 0.511773s, Loss: 0.338221
48,LA_T_3627265,1,44402,64000, 54/118, Time: 0.511773s, Loss: 0.338221
27,LA_T_2419035,0,64000,0, 55/118, Time: 0.511773s, Loss: 0.338221
89,LA_T_7124444,0,64000,0, 56/118, Time: 0.511773s, Loss: 0.338221
2,LA_T_1346935,0,45741,0, 57/118, Time: 0.511773s, Loss: 0.338221
95,LA_T_7314513,0,39437,0, 58/118, Time: 0.511773s, Loss: 0.338221
40,LA_T_3319380,0,42032,0, 59/118, Time: 0.511773s, Loss: 0.338221
96,LA_T_7359423,0,50164,0, 60/118, Time: 0.511773s, Loss: 0.338221
99,LA_T_7529623,0,43309,0, 61/118, Time: 0.511773s, Loss: 0.338221
66,LA_T_5433188,0,34172,0, 62/118, Time: 0.511773s, Loss: 0.338221
5,LA_T_1486451,0,50406,0, 63/118, Time: 0.511773s, Loss: 0.338221
81,LA_T_6521388,0,64000,0, 64/118, Time: 0.511773s, Loss: 0.338221
12,LA_T_1653822,1,9756,64000, 65/118, Time: 0.559850s, Loss: 0.314111
14,LA_T_1836557,0,43646,0, 66/118, Time: 0.559850s, Loss: 0.314111
77,LA_T_6390981,0,64000,0, 67/118, Time: 0.559850s, Loss: 0.314111
34,LA_T_3021659,1,10227,64000, 68/118, Time: 0.559850s, Loss: 0.314111
33,LA_T_3021659,0,64000,0, 69/118, Time: 0.559850s, Loss: 0.314111
6,LA_T_1490244,0,55572,0, 70/118, Time: 0.559850s, Loss: 0.314111
50,LA_T_3935691,0,39156,0, 71/118, Time: 0.559850s, Loss: 0.314111
68,LA_T_5522733,0,61381,0, 72/118, Time: 0.559850s, Loss: 0.314111
18,LA_T_1909651,2,24481,128000, 73/118, Time: 0.559850s, Loss: 0.314111
80,LA_T_6487227,0,44111,0, 74/118, Time: 0.559850s, Loss: 0.314111
73,LA_T_5978739,0,33363,0, 75/118, Time: 0.559850s, Loss: 0.314111
70,LA_T_5883755,0,64000,0, 76/118, Time: 0.559850s, Loss: 0.314111
56,LA_T_4725126,0,61141,0, 77/118, Time: 0.559850s, Loss: 0.314111
103,LA_T_7866363,0,63473,0, 78/118, Time: 0.559850s, Loss: 0.314111
59,LA_T_5015679,0,41144,0, 79/118, Time: 0.559850s, Loss: 0.314111
41,LA_T_3391018,0,57402,0, 80/118, Time: 0.559850s, Loss: 0.314111
63,LA_T_5214047,0,41920,0, 81/118, Time: 0.559850s, Loss: 0.314111
28,LA_T_2419035,1,10625,64000, 82/118, Time: 0.559850s, Loss: 0.314111
113,LA_T_9633872,0,27407,0, 83/118, Time: 0.559850s, Loss: 0.314111
57,LA_T_4774044,0,59379,0, 84/118, Time: 0.559850s, Loss: 0.314111
86,LA_T_6941395,1,29307,64000, 85/118, Time: 0.559850s, Loss: 0.314111
104,LA_T_7888797,0,26626,0, 86/118, Time: 0.559850s, Loss: 0.314111
16,LA_T_1909651,0,64000,0, 87/118, Time: 0.559850s, Loss: 0.314111
45,LA_T_3527643,1,8295,64000, 88/118, Time: 0.559850s, Loss: 0.314111
31,LA_T_2677562,0,63649,0, 89/118, Time: 0.559850s, Loss: 0.314111
65,LA_T_5360018,0,54554,0, 90/118, Time: 0.559850s, Loss: 0.314111
52,LA_T_4096754,0,31273,0, 91/118, Time: 0.559850s, Loss: 0.314111
101,LA_T_7706110,0,24083,0, 92/118, Time: 0.559850s, Loss: 0.314111
60,LA_T_5205025,0,61550,0, 93/118, Time: 0.559850s, Loss: 0.314111
10,LA_T_1630611,0,58109,0, 94/118, Time: 0.559850s, Loss: 0.314111
75,LA_T_6331069,0,64000,0, 95/118, Time: 0.559850s, Loss: 0.314111
17,LA_T_1909651,1,64000,64000, 96/118, Time: 0.559850s, Loss: 0.314111
39,LA_T_3250806,0,61271,0, 97/118, Time: 0.559850s, Loss: 0.314111
88,LA_T_7020532,0,59863,0, 98/118, Time: 0.559850s, Loss: 0.314111
116,LA_T_9746209,1,16967,64000, 99/118, Time: 0.559850s, Loss: 0.314111
8,LA_T_1589546,0,64000,0, 100/118, Time: 0.559850s, Loss: 0.314111
82,LA_T_6728875,0,64000,0, 101/118, Time: 0.559850s, Loss: 0.314111
92,LA_T_7273305,0,53173,0, 102/118, Time: 0.559850s, Loss: 0.314111
15,LA_T_1870524,0,43190,0, 103/118, Time: 0.559850s, Loss: 0.314111
84,LA_T_6822716,0,27313,0, 104/118, Time: 0.559850s, Loss: 0.314111
79,LA_T_6476207,0,54948,0, 105/118, Time: 0.559850s, Loss: 0.314111
37,LA_T_3189628,1,15851,64000, 106/118, Time: 0.559850s, Loss: 0.314111
106,LA_T_8090857,0,64000,0, 107/118, Time: 0.559850s, Loss: 0.314111
61,LA_T_5209704,0,64000,0, 108/118, Time: 0.559850s, Loss: 0.314111
36,LA_T_3189628,0,64000,0, 109/118, Time: 0.559850s, Loss: 0.314111
21,LA_T_2277153,0,64000,0, 110/118, Time: 0.559850s, Loss: 0.314111
26,LA_T_2354581,0,47687,0, 111/118, Time: 0.559850s, Loss: 0.314111
109,LA_T_8527420,0,63377,0, 112/118, Time: 0.559850s, Loss: 0.314111
46,LA_T_3588714,0,46298,0, 113/118, Time: 0.559850s, Loss: 0.314111
64,LA_T_5258800,0,54370,0, 114/118, Time: 0.559850s, Loss: 0.314111
91,LA_T_7223887,0,40210,0, 115/118, Time: 0.559850s, Loss: 0.314111
94,LA_T_7281115,1,11690,64000, 116/118, Time: 0.559850s, Loss: 0.314111
87,LA_T_6960076,0,42296,0, 117/118, Time: 0.559850s, Loss: 0.314111
0,LA_T_1154440,0,30107,0, 118/118, Time: 0.559850s, Loss: 0.314111
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
19,LA_D_4013191,0,34443,0, 1/63, Time: 0.258172s, Loss: 0.280296
48,LA_D_7869978,1,20551,64000, 2/63, Time: 0.258172s, Loss: 0.280296
60,LA_D_9686838,1,28544,64000, 3/63, Time: 0.258172s, Loss: 0.280296
41,LA_D_6180779,0,23109,0, 4/63, Time: 0.258172s, Loss: 0.280296
18,LA_D_3983088,0,21649,0, 5/63, Time: 0.258172s, Loss: 0.280296
16,LA_D_3457616,0,51111,0, 6/63, Time: 0.258172s, Loss: 0.280296
59,LA_D_9686838,0,64000,0, 7/63, Time: 0.258172s, Loss: 0.280296
29,LA_D_5300881,1,27489,64000, 8/63, Time: 0.258172s, Loss: 0.280296
2,LA_D_1317561,0,64000,0, 9/63, Time: 0.258172s, Loss: 0.280296
9,LA_D_2082512,0,53318,0, 10/63, Time: 0.258172s, Loss: 0.280296
37,LA_D_5891869,0,54006,0, 11/63, Time: 0.258172s, Loss: 0.280296
22,LA_D_4394367,0,61722,0, 12/63, Time: 0.258172s, Loss: 0.280296
26,LA_D_5239066,0,64000,0, 13/63, Time: 0.258172s, Loss: 0.280296
47,LA_D_7869978,0,64000,0, 14/63, Time: 0.258172s, Loss: 0.280296
61,LA_D_9753761,0,64000,0, 15/63, Time: 0.258172s, Loss: 0.280296
30,LA_D_5441528,0,24518,0, 16/63, Time: 0.258172s, Loss: 0.280296
56,LA_D_9316963,0,58699,0, 17/63, Time: 0.258172s, Loss: 0.280296
44,LA_D_7095518,0,56482,0, 18/63, Time: 0.258172s, Loss: 0.280296
33,LA_D_5659407,0,64000,0, 19/63, Time: 0.258172s, Loss: 0.280296
10,LA_D_2648941,0,64000,0, 20/63, Time: 0.258172s, Loss: 0.280296
4,LA_D_1366945,0,45986,0, 21/63, Time: 0.258172s, Loss: 0.280296
45,LA_D_7452217,0,25016,0, 22/63, Time: 0.258172s, Loss: 0.280296
21,LA_D_4276413,0,49755,0, 23/63, Time: 0.258172s, Loss: 0.280296
51,LA_D_8228250,0,42344,0, 24/63, Time: 0.258172s, Loss: 0.280296
15,LA_D_3203408,0,49607,0, 25/63, Time: 0.258172s, Loss: 0.280296
20,LA_D_4265541,0,26061,0, 26/63, Time: 0.258172s, Loss: 0.280296
55,LA_D_9192205,0,40612,0, 27/63, Time: 0.258172s, Loss: 0.280296
28,LA_D_5300881,0,64000,0, 28/63, Time: 0.258172s, Loss: 0.280296
35,LA_D_5835948,0,64000,0, 29/63, Time: 0.258172s, Loss: 0.280296
13,LA_D_2949136,0,64000,0, 30/63, Time: 0.258172s, Loss: 0.280296
32,LA_D_5505879,1,35600,64000, 31/63, Time: 0.258172s, Loss: 0.280296
0,LA_D_1179848,0,64000,0, 32/63, Time: 0.258172s, Loss: 0.280296
7,LA_D_1803008,0,45707,0, 33/63, Time: 0.258172s, Loss: 0.280296
46,LA_D_7862876,0,57311,0, 34/63, Time: 0.258172s, Loss: 0.280296
5,LA_D_1435765,0,47544,0, 35/63, Time: 0.258172s, Loss: 0.280296
25,LA_D_4630224,0,27639,0, 36/63, Time: 0.258172s, Loss: 0.280296
36,LA_D_5835948,1,29523,64000, 37/63, Time: 0.258172s, Loss: 0.280296
39,LA_D_5944972,1,39788,64000, 38/63, Time: 0.258172s, Loss: 0.280296
17,LA_D_3705418,0,64000,0, 39/63, Time: 0.258172s, Loss: 0.280296
38,LA_D_5944972,0,64000,0, 40/63, Time: 0.258172s, Loss: 0.280296
50,LA_D_7974256,0,50504,0, 41/63, Time: 0.258172s, Loss: 0.280296
11,LA_D_2648941,1,41414,64000, 42/63, Time: 0.258172s, Loss: 0.280296
53,LA_D_8584336,0,61424,0, 43/63, Time: 0.258172s, Loss: 0.280296
14,LA_D_2949136,1,27301,64000, 44/63, Time: 0.258172s, Loss: 0.280296
54,LA_D_8998984,0,37498,0, 45/63, Time: 0.258172s, Loss: 0.280296
62,LA_D_9753761,1,22997,64000, 46/63, Time: 0.258172s, Loss: 0.280296
57,LA_D_9493396,0,40904,0, 47/63, Time: 0.258172s, Loss: 0.280296
23,LA_D_4519635,0,64000,0, 48/63, Time: 0.258172s, Loss: 0.280296
52,LA_D_8284460,0,50174,0, 49/63, Time: 0.258172s, Loss: 0.280296
24,LA_D_4519635,1,12487,64000, 50/63, Time: 0.258172s, Loss: 0.280296
3,LA_D_1317561,1,8976,64000, 51/63, Time: 0.258172s, Loss: 0.280296
49,LA_D_7933136,0,64000,0, 52/63, Time: 0.258172s, Loss: 0.280296
58,LA_D_9566347,0,35349,0, 53/63, Time: 0.258172s, Loss: 0.280296
6,LA_D_1580841,0,38838,0, 54/63, Time: 0.258172s, Loss: 0.280296
42,LA_D_6502788,0,29166,0, 55/63, Time: 0.258172s, Loss: 0.280296
40,LA_D_6055606,0,53176,0, 56/63, Time: 0.258172s, Loss: 0.280296
12,LA_D_2896709,0,64000,0, 57/63, Time: 0.258172s, Loss: 0.280296
31,LA_D_5505879,0,64000,0, 58/63, Time: 0.258172s, Loss: 0.280296
43,LA_D_7026375,0,61915,0, 59/63, Time: 0.258172s, Loss: 0.280296
34,LA_D_5741681,0,44990,0, 60/63, Time: 0.258172s, Loss: 0.280296
8,LA_D_1886178,0,40092,0, 61/63, Time: 0.258172s, Loss: 0.280296
27,LA_D_5239066,1,30014,64000, 62/63, Time: 0.258172s, Loss: 0.280296
1,LA_D_1179848,1,29541,64000, 63/63, Time: 0.258172s, Loss: 0.280296
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
100,LA_T_7550620,0,44981,0, 1/118, Time: 0.493630s, Loss: 0.304187
94,LA_T_7281115,1,11690,64000, 2/118, Time: 0.493630s, Loss: 0.304187
79,LA_T_6476207,0,54948,0, 3/118, Time: 0.493630s, Loss: 0.304187
65,LA_T_5360018,0,54554,0, 4/118, Time: 0.493630s, Loss: 0.304187
27,LA_T_2419035,0,64000,0, 5/118, Time: 0.493630s, Loss: 0.304187
72,LA_T_5894355,0,64000,0, 6/118, Time: 0.493630s, Loss: 0.304187
31,LA_T_2677562,0,63649,0, 7/118, Time: 0.493630s, Loss: 0.304187
64,LA_T_5258800,0,54370,0, 8/118, Time: 0.493630s, Loss: 0.304187
4,LA_T_1470918,0,39641,0, 9/118, Time: 0.493630s, Loss: 0.304187
105,LA_T_8007992,0,45465,0, 10/118, Time: 0.493630s, Loss: 0.304187
46,LA_T_3588714,0,46298,0, 11/118, Time: 0.493630s, Loss: 0.304187
110,LA_T_8681550,0,40836,0, 12/118, Time: 0.493630s, Loss: 0.304187
8,LA_T_1589546,0,64000,0, 13/118, Time: 0.493630s, Loss: 0.304187
53,LA_T_4512109,0,51563,0, 14/118, Time: 0.493630s, Loss: 0.304187
116,LA_T_9746209,1,16967,64000, 15/118, Time: 0.493630s, Loss: 0.304187
3,LA_T_1373588,0,46949,0, 16/118, Time: 0.493630s, Loss: 0.304187
52,LA_T_4096754,0,31273,0, 17/118, Time: 0.493630s, Loss: 0.304187
2,LA_T_1346935,0,45741,0, 18/118, Time: 0.493630s, Loss: 0.304187
48,LA_T_3627265,1,44402,64000, 19/118, Time: 0.493630s, Loss: 0.304187
73,LA_T_5978739,0,33363,0, 20/118, Time: 0.493630s, Loss: 0.304187
96,LA_T_7359423,0,50164,0, 21/118, Time: 0.493630s, Loss: 0.304187
5,LA_T_1486451,0,50406,0, 22/118, Time: 0.493630s, Loss: 0.304187
28,LA_T_2419035,1,10625,64000, 23/118, Time: 0.493630s, Loss: 0.304187
57,LA_T_4774044,0,59379,0, 24/118, Time: 0.493630s, Loss: 0.304187
18,LA_T_1909651,2,24481,128000, 25/118, Time: 0.493630s, Loss: 0.304187
0,LA_T_1154440,0,30107,0, 26/118, Time: 0.493630s, Loss: 0.304187
50,LA_T_3935691,0,39156,0, 27/118, Time: 0.493630s, Loss: 0.304187
14,LA_T_1836557,0,43646,0, 28/118, Time: 0.493630s, Loss: 0.304187
25,LA_T_2333843,0,61708,0, 29/118, Time: 0.493630s, Loss: 0.304187
62,LA_T_5209704,1,34511,64000, 30/118, Time: 0.493630s, Loss: 0.304187
35,LA_T_3176741,0,62198,0, 31/118, Time: 0.493630s, Loss: 0.304187
99,LA_T_7529623,0,43309,0, 32/118, Time: 0.493630s, Loss: 0.304187
66,LA_T_5433188,0,34172,0, 33/118, Time: 0.493630s, Loss: 0.304187
112,LA_T_9540683,0,25430,0, 34/118, Time: 0.493630s, Loss: 0.304187
32,LA_T_2995069,0,49112,0, 35/118, Time: 0.493630s, Loss: 0.304187
67,LA_T_5492534,0,28365,0, 36/118, Time: 0.493630s, Loss: 0.304187
42,LA_T_3467377,0,64000,0, 37/118, Time: 0.493630s, Loss: 0.304187
113,LA_T_9633872,0,27407,0, 38/118, Time: 0.493630s, Loss: 0.304187
108,LA_T_8234484,0,46183,0, 39/118, Time: 0.493630s, Loss: 0.304187
87,LA_T_6960076,0,42296,0, 40/118, Time: 0.493630s, Loss: 0.304187
13,LA_T_1724943,0,60906,0, 41/118, Time: 0.493630s, Loss: 0.304187
111,LA_T_9226984,0,45529,0, 42/118, Time: 0.493630s, Loss: 0.304187
16,LA_T_1909651,0,64000,0, 43/118, Time: 0.493630s, Loss: 0.304187
56,LA_T_4725126,0,61141,0, 44/118, Time: 0.493630s, Loss: 0.304187
47,LA_T_3627265,0,64000,0, 45/118, Time: 0.493630s, Loss: 0.304187
44,LA_T_3527643,0,64000,0, 46/118, Time: 0.493630s, Loss: 0.304187
60,LA_T_5205025,0,61550,0, 47/118, Time: 0.493630s, Loss: 0.304187
29,LA_T_2422854,0,62661,0, 48/118, Time: 0.493630s, Loss: 0.304187
117,LA_T_9830298,0,64000,0, 49/118, Time: 0.493630s, Loss: 0.304187
104,LA_T_7888797,0,26626,0, 50/118, Time: 0.493630s, Loss: 0.304187
10,LA_T_1630611,0,58109,0, 51/118, Time: 0.493630s, Loss: 0.304187
38,LA_T_3220265,0,38149,0, 52/118, Time: 0.493630s, Loss: 0.304187
81,LA_T_6521388,0,64000,0, 53/118, Time: 0.493630s, Loss: 0.304187
88,LA_T_7020532,0,59863,0, 54/118, Time: 0.493630s, Loss: 0.304187
98,LA_T_7422011,0,45646,0, 55/118, Time: 0.493630s, Loss: 0.304187
43,LA_T_3467377,1,26131,64000, 56/118, Time: 0.493630s, Loss: 0.304187
77,LA_T_6390981,0,64000,0, 57/118, Time: 0.493630s, Loss: 0.304187
36,LA_T_3189628,0,64000,0, 58/118, Time: 0.493630s, Loss: 0.304187
6,LA_T_1490244,0,55572,0, 59/118, Time: 0.493630s, Loss: 0.304187
74,LA_T_6301739,0,41843,0, 60/118, Time: 0.493630s, Loss: 0.304187
115,LA_T_9746209,0,64000,0, 61/118, Time: 0.493630s, Loss: 0.304187
59,LA_T_5015679,0,41144,0, 62/118, Time: 0.493630s, Loss: 0.304187
103,LA_T_7866363,0,63473,0, 63/118, Time: 0.493630s, Loss: 0.304187
19,LA_T_2052267,0,38415,0, 64/118, Time: 0.493630s, Loss: 0.304187
95,LA_T_7314513,0,39437,0, 65/118, Time: 0.547481s, Loss: 0.360425
40,LA_T_3319380,0,42032,0, 66/118, Time: 0.547481s, Loss: 0.360425
93,LA_T_7281115,0,64000,0, 67/118, Time: 0.547481s, Loss: 0.360425
23,LA_T_2320617,0,56846,0, 68/118, Time: 0.547481s, Loss: 0.360425
68,LA_T_5522733,0,61381,0, 69/118, Time: 0.547481s, Loss: 0.360425
90,LA_T_7124444,1,21405,64000, 70/118, Time: 0.547481s, Loss: 0.360425
9,LA_T_1589546,1,9736,64000, 71/118, Time: 0.547481s, Loss: 0.360425
97,LA_T_7405543,0,36914,0, 72/118, Time: 0.547481s, Loss: 0.360425
114,LA_T_9668514,0,54564,0, 73/118, Time: 0.547481s, Loss: 0.360425
109,LA_T_8527420,0,63377,0, 74/118, Time: 0.547481s, Loss: 0.360425
82,LA_T_6728875,0,64000,0, 75/118, Time: 0.547481s, Loss: 0.360425
83,LA_T_6751630,0,62290,0, 76/118, Time: 0.547481s, Loss: 0.360425
7,LA_T_1518499,0,29284,0, 77/118, Time: 0.547481s, Loss: 0.360425
1,LA_T_1258641,0,44562,0, 78/118, Time: 0.547481s, Loss: 0.360425
75,LA_T_6331069,0,64000,0, 79/118, Time: 0.547481s, Loss: 0.360425
37,LA_T_3189628,1,15851,64000, 80/118, Time: 0.547481s, Loss: 0.360425
49,LA_T_3758169,0,46047,0, 81/118, Time: 0.547481s, Loss: 0.360425
85,LA_T_6941395,0,64000,0, 82/118, Time: 0.547481s, Loss: 0.360425
55,LA_T_4630359,0,64000,0, 83/118, Time: 0.547481s, Loss: 0.360425
86,LA_T_6941395,1,29307,64000, 84/118, Time: 0.547481s, Loss: 0.360425
39,LA_T_3250806,0,61271,0, 85/118, Time: 0.547481s, Loss: 0.360425
70,LA_T_5883755,0,64000,0, 86/118, Time: 0.547481s, Loss: 0.360425
78,LA_T_6435787,0,43614,0, 87/118, Time: 0.547481s, Loss: 0.360425
91,LA_T_7223887,0,40210,0, 88/118, Time: 0.547481s, Loss: 0.360425
11,LA_T_1653822,0,64000,0, 89/118, Time: 0.547481s, Loss: 0.360425
106,LA_T_8090857,0,64000,0, 90/118, Time: 0.547481s, Loss: 0.360425
63,LA_T_5214047,0,41920,0, 91/118, Time: 0.547481s, Loss: 0.360425
102,LA_T_7808689,0,64000,0, 92/118, Time: 0.547481s, Loss: 0.360425
107,LA_T_8206162,0,55328,0, 93/118, Time: 0.547481s, Loss: 0.360425
26,LA_T_2354581,0,47687,0, 94/118, Time: 0.547481s, Loss: 0.360425
17,LA_T_1909651,1,64000,64000, 95/118, Time: 0.547481s, Loss: 0.360425
61,LA_T_5209704,0,64000,0, 96/118, Time: 0.547481s, Loss: 0.360425
71,LA_T_5883755,1,19926,64000, 97/118, Time: 0.547481s, Loss: 0.360425
89,LA_T_7124444,0,64000,0, 98/118, Time: 0.547481s, Loss: 0.360425
84,LA_T_6822716,0,27313,0, 99/118, Time: 0.547481s, Loss: 0.360425
80,LA_T_6487227,0,44111,0, 100/118, Time: 0.547481s, Loss: 0.360425
22,LA_T_2277153,1,21822,64000, 101/118, Time: 0.547481s, Loss: 0.360425
76,LA_T_6331069,1,64000,64000, 102/118, Time: 0.547481s, Loss: 0.360425
41,LA_T_3391018,0,57402,0, 103/118, Time: 0.547481s, Loss: 0.360425
12,LA_T_1653822,1,9756,64000, 104/118, Time: 0.547481s, Loss: 0.360425
24,LA_T_2327393,0,60701,0, 105/118, Time: 0.547481s, Loss: 0.360425
58,LA_T_4928920,0,64000,0, 106/118, Time: 0.547481s, Loss: 0.360425
45,LA_T_3527643,1,8295,64000, 107/118, Time: 0.547481s, Loss: 0.360425
34,LA_T_3021659,1,10227,64000, 108/118, Time: 0.547481s, Loss: 0.360425
92,LA_T_7273305,0,53173,0, 109/118, Time: 0.547481s, Loss: 0.360425
101,LA_T_7706110,0,24083,0, 110/118, Time: 0.547481s, Loss: 0.360425
69,LA_T_5786445,0,64000,0, 111/118, Time: 0.547481s, Loss: 0.360425
54,LA_T_4584407,0,36921,0, 112/118, Time: 0.547481s, Loss: 0.360425
33,LA_T_3021659,0,64000,0, 113/118, Time: 0.547481s, Loss: 0.360425
15,LA_T_1870524,0,43190,0, 114/118, Time: 0.547481s, Loss: 0.360425
51,LA_T_3993688,0,48709,0, 115/118, Time: 0.547481s, Loss: 0.360425
21,LA_T_2277153,0,64000,0, 116/118, Time: 0.547481s, Loss: 0.360425
30,LA_T_2584761,0,47107,0, 117/118, Time: 0.547481s, Loss: 0.360425
20,LA_T_2269038,0,63442,0, 118/118, Time: 0.547481s, Loss: 0.360425
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
7,LA_D_1803008,0,45707,0, 1/63, Time: 0.250318s, Loss: 0.279322
50,LA_D_7974256,0,50504,0, 2/63, Time: 0.250318s, Loss: 0.279322
16,LA_D_3457616,0,51111,0, 3/63, Time: 0.250318s, Loss: 0.279322
39,LA_D_5944972,1,39788,64000, 4/63, Time: 0.250318s, Loss: 0.279322
15,LA_D_3203408,0,49607,0, 5/63, Time: 0.250318s, Loss: 0.279322
36,LA_D_5835948,1,29523,64000, 6/63, Time: 0.250318s, Loss: 0.279322
44,LA_D_7095518,0,56482,0, 7/63, Time: 0.250318s, Loss: 0.279322
48,LA_D_7869978,1,20551,64000, 8/63, Time: 0.250318s, Loss: 0.279322
47,LA_D_7869978,0,64000,0, 9/63, Time: 0.250318s, Loss: 0.279322
21,LA_D_4276413,0,49755,0, 10/63, Time: 0.250318s, Loss: 0.279322
18,LA_D_3983088,0,21649,0, 11/63, Time: 0.250318s, Loss: 0.279322
10,LA_D_2648941,0,64000,0, 12/63, Time: 0.250318s, Loss: 0.279322
35,LA_D_5835948,0,64000,0, 13/63, Time: 0.250318s, Loss: 0.279322
5,LA_D_1435765,0,47544,0, 14/63, Time: 0.250318s, Loss: 0.279322
20,LA_D_4265541,0,26061,0, 15/63, Time: 0.250318s, Loss: 0.279322
31,LA_D_5505879,0,64000,0, 16/63, Time: 0.250318s, Loss: 0.279322
51,LA_D_8228250,0,42344,0, 17/63, Time: 0.250318s, Loss: 0.279322
45,LA_D_7452217,0,25016,0, 18/63, Time: 0.250318s, Loss: 0.279322
34,LA_D_5741681,0,44990,0, 19/63, Time: 0.250318s, Loss: 0.279322
37,LA_D_5891869,0,54006,0, 20/63, Time: 0.250318s, Loss: 0.279322
40,LA_D_6055606,0,53176,0, 21/63, Time: 0.250318s, Loss: 0.279322
14,LA_D_2949136,1,27301,64000, 22/63, Time: 0.250318s, Loss: 0.279322
4,LA_D_1366945,0,45986,0, 23/63, Time: 0.250318s, Loss: 0.279322
11,LA_D_2648941,1,41414,64000, 24/63, Time: 0.250318s, Loss: 0.279322
1,LA_D_1179848,1,29541,64000, 25/63, Time: 0.250318s, Loss: 0.279322
58,LA_D_9566347,0,35349,0, 26/63, Time: 0.250318s, Loss: 0.279322
61,LA_D_9753761,0,64000,0, 27/63, Time: 0.250318s, Loss: 0.279322
9,LA_D_2082512,0,53318,0, 28/63, Time: 0.250318s, Loss: 0.279322
24,LA_D_4519635,1,12487,64000, 29/63, Time: 0.250318s, Loss: 0.279322
3,LA_D_1317561,1,8976,64000, 30/63, Time: 0.250318s, Loss: 0.279322
30,LA_D_5441528,0,24518,0, 31/63, Time: 0.250318s, Loss: 0.279322
27,LA_D_5239066,1,30014,64000, 32/63, Time: 0.250318s, Loss: 0.279322
13,LA_D_2949136,0,64000,0, 33/63, Time: 0.250318s, Loss: 0.279322
43,LA_D_7026375,0,61915,0, 34/63, Time: 0.250318s, Loss: 0.279322
8,LA_D_1886178,0,40092,0, 35/63, Time: 0.250318s, Loss: 0.279322
17,LA_D_3705418,0,64000,0, 36/63, Time: 0.250318s, Loss: 0.279322
59,LA_D_9686838,0,64000,0, 37/63, Time: 0.250318s, Loss: 0.279322
28,LA_D_5300881,0,64000,0, 38/63, Time: 0.250318s, Loss: 0.279322
2,LA_D_1317561,0,64000,0, 39/63, Time: 0.250318s, Loss: 0.279322
19,LA_D_4013191,0,34443,0, 40/63, Time: 0.250318s, Loss: 0.279322
56,LA_D_9316963,0,58699,0, 41/63, Time: 0.250318s, Loss: 0.279322
23,LA_D_4519635,0,64000,0, 42/63, Time: 0.250318s, Loss: 0.279322
25,LA_D_4630224,0,27639,0, 43/63, Time: 0.250318s, Loss: 0.279322
41,LA_D_6180779,0,23109,0, 44/63, Time: 0.250318s, Loss: 0.279322
12,LA_D_2896709,0,64000,0, 45/63, Time: 0.250318s, Loss: 0.279322
46,LA_D_7862876,0,57311,0, 46/63, Time: 0.250318s, Loss: 0.279322
60,LA_D_9686838,1,28544,64000, 47/63, Time: 0.250318s, Loss: 0.279322
54,LA_D_8998984,0,37498,0, 48/63, Time: 0.250318s, Loss: 0.279322
32,LA_D_5505879,1,35600,64000, 49/63, Time: 0.250318s, Loss: 0.279322
57,LA_D_9493396,0,40904,0, 50/63, Time: 0.250318s, Loss: 0.279322
22,LA_D_4394367,0,61722,0, 51/63, Time: 0.250318s, Loss: 0.279322
42,LA_D_6502788,0,29166,0, 52/63, Time: 0.250318s, Loss: 0.279322
62,LA_D_9753761,1,22997,64000, 53/63, Time: 0.250318s, Loss: 0.279322
49,LA_D_7933136,0,64000,0, 54/63, Time: 0.250318s, Loss: 0.279322
29,LA_D_5300881,1,27489,64000, 55/63, Time: 0.250318s, Loss: 0.279322
33,LA_D_5659407,0,64000,0, 56/63, Time: 0.250318s, Loss: 0.279322
55,LA_D_9192205,0,40612,0, 57/63, Time: 0.250318s, Loss: 0.279322
38,LA_D_5944972,0,64000,0, 58/63, Time: 0.250318s, Loss: 0.279322
6,LA_D_1580841,0,38838,0, 59/63, Time: 0.250318s, Loss: 0.279322
53,LA_D_8584336,0,61424,0, 60/63, Time: 0.250318s, Loss: 0.279322
26,LA_D_5239066,0,64000,0, 61/63, Time: 0.250318s, Loss: 0.279322
52,LA_D_8284460,0,50174,0, 62/63, Time: 0.250318s, Loss: 0.279322
0,LA_D_1179848,0,64000,0, 63/63, Time: 0.250318s, Loss: 0.279322
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
73,LA_T_5978739,0,33363,0, 1/118, Time: 0.511197s, Loss: 0.323043
84,LA_T_6822716,0,27313,0, 2/118, Time: 0.511197s, Loss: 0.323043
68,LA_T_5522733,0,61381,0, 3/118, Time: 0.511197s, Loss: 0.323043
79,LA_T_6476207,0,54948,0, 4/118, Time: 0.511197s, Loss: 0.323043
4,LA_T_1470918,0,39641,0, 5/118, Time: 0.511197s, Loss: 0.323043
17,LA_T_1909651,1,64000,64000, 6/118, Time: 0.511197s, Loss: 0.323043
111,LA_T_9226984,0,45529,0, 7/118, Time: 0.511197s, Loss: 0.323043
27,LA_T_2419035,0,64000,0, 8/118, Time: 0.511197s, Loss: 0.323043
102,LA_T_7808689,0,64000,0, 9/118, Time: 0.511197s, Loss: 0.323043
15,LA_T_1870524,0,43190,0, 10/118, Time: 0.511197s, Loss: 0.323043
1,LA_T_1258641,0,44562,0, 11/118, Time: 0.511197s, Loss: 0.323043
114,LA_T_9668514,0,54564,0, 12/118, Time: 0.511197s, Loss: 0.323043
22,LA_T_2277153,1,21822,64000, 13/118, Time: 0.511197s, Loss: 0.323043
23,LA_T_2320617,0,56846,0, 14/118, Time: 0.511197s, Loss: 0.323043
50,LA_T_3935691,0,39156,0, 15/118, Time: 0.511197s, Loss: 0.323043
13,LA_T_1724943,0,60906,0, 16/118, Time: 0.511197s, Loss: 0.323043
51,LA_T_3993688,0,48709,0, 17/118, Time: 0.511197s, Loss: 0.323043
109,LA_T_8527420,0,63377,0, 18/118, Time: 0.511197s, Loss: 0.323043
90,LA_T_7124444,1,21405,64000, 19/118, Time: 0.511197s, Loss: 0.323043
94,LA_T_7281115,1,11690,64000, 20/118, Time: 0.511197s, Loss: 0.323043
103,LA_T_7866363,0,63473,0, 21/118, Time: 0.511197s, Loss: 0.323043
86,LA_T_6941395,1,29307,64000, 22/118, Time: 0.511197s, Loss: 0.323043
39,LA_T_3250806,0,61271,0, 23/118, Time: 0.511197s, Loss: 0.323043
36,LA_T_3189628,0,64000,0, 24/118, Time: 0.511197s, Loss: 0.323043
43,LA_T_3467377,1,26131,64000, 25/118, Time: 0.511197s, Loss: 0.323043
91,LA_T_7223887,0,40210,0, 26/118, Time: 0.511197s, Loss: 0.323043
12,LA_T_1653822,1,9756,64000, 27/118, Time: 0.511197s, Loss: 0.323043
25,LA_T_2333843,0,61708,0, 28/118, Time: 0.511197s, Loss: 0.323043
7,LA_T_1518499,0,29284,0, 29/118, Time: 0.511197s, Loss: 0.323043
61,LA_T_5209704,0,64000,0, 30/118, Time: 0.511197s, Loss: 0.323043
34,LA_T_3021659,1,10227,64000, 31/118, Time: 0.511197s, Loss: 0.323043
40,LA_T_3319380,0,42032,0, 32/118, Time: 0.511197s, Loss: 0.323043
53,LA_T_4512109,0,51563,0, 33/118, Time: 0.511197s, Loss: 0.323043
54,LA_T_4584407,0,36921,0, 34/118, Time: 0.511197s, Loss: 0.323043
83,LA_T_6751630,0,62290,0, 35/118, Time: 0.511197s, Loss: 0.323043
28,LA_T_2419035,1,10625,64000, 36/118, Time: 0.511197s, Loss: 0.323043
48,LA_T_3627265,1,44402,64000, 37/118, Time: 0.511197s, Loss: 0.323043
110,LA_T_8681550,0,40836,0, 38/118, Time: 0.511197s, Loss: 0.323043
42,LA_T_3467377,0,64000,0, 39/118, Time: 0.511197s, Loss: 0.323043
101,LA_T_7706110,0,24083,0, 40/118, Time: 0.511197s, Loss: 0.323043
100,LA_T_7550620,0,44981,0, 41/118, Time: 0.511197s, Loss: 0.323043
75,LA_T_6331069,0,64000,0, 42/118, Time: 0.511197s, Loss: 0.323043
47,LA_T_3627265,0,64000,0, 43/118, Time: 0.511197s, Loss: 0.323043
9,LA_T_1589546,1,9736,64000, 44/118, Time: 0.511197s, Loss: 0.323043
21,LA_T_2277153,0,64000,0, 45/118, Time: 0.511197s, Loss: 0.323043
85,LA_T_6941395,0,64000,0, 46/118, Time: 0.511197s, Loss: 0.323043
117,LA_T_9830298,0,64000,0, 47/118, Time: 0.511197s, Loss: 0.323043
58,LA_T_4928920,0,64000,0, 48/118, Time: 0.511197s, Loss: 0.323043
37,LA_T_3189628,1,15851,64000, 49/118, Time: 0.511197s, Loss: 0.323043
0,LA_T_1154440,0,30107,0, 50/118, Time: 0.511197s, Loss: 0.323043
16,LA_T_1909651,0,64000,0, 51/118, Time: 0.511197s, Loss: 0.323043
82,LA_T_6728875,0,64000,0, 52/118, Time: 0.511197s, Loss: 0.323043
80,LA_T_6487227,0,44111,0, 53/118, Time: 0.511197s, Loss: 0.323043
44,LA_T_3527643,0,64000,0, 54/118, Time: 0.511197s, Loss: 0.323043
72,LA_T_5894355,0,64000,0, 55/118, Time: 0.511197s, Loss: 0.323043
52,LA_T_4096754,0,31273,0, 56/118, Time: 0.511197s, Loss: 0.323043
81,LA_T_6521388,0,64000,0, 57/118, Time: 0.511197s, Loss: 0.323043
38,LA_T_3220265,0,38149,0, 58/118, Time: 0.511197s, Loss: 0.323043
33,LA_T_3021659,0,64000,0, 59/118, Time: 0.511197s, Loss: 0.323043
2,LA_T_1346935,0,45741,0, 60/118, Time: 0.511197s, Loss: 0.323043
87,LA_T_6960076,0,42296,0, 61/118, Time: 0.511197s, Loss: 0.323043
26,LA_T_2354581,0,47687,0, 62/118, Time: 0.511197s, Loss: 0.323043
67,LA_T_5492534,0,28365,0, 63/118, Time: 0.511197s, Loss: 0.323043
10,LA_T_1630611,0,58109,0, 64/118, Time: 0.511197s, Loss: 0.323043
29,LA_T_2422854,0,62661,0, 65/118, Time: 0.560798s, Loss: 0.301867
97,LA_T_7405543,0,36914,0, 66/118, Time: 0.560798s, Loss: 0.301867
96,LA_T_7359423,0,50164,0, 67/118, Time: 0.560798s, Loss: 0.301867
71,LA_T_5883755,1,19926,64000, 68/118, Time: 0.560798s, Loss: 0.301867
92,LA_T_7273305,0,53173,0, 69/118, Time: 0.560798s, Loss: 0.301867
69,LA_T_5786445,0,64000,0, 70/118, Time: 0.560798s, Loss: 0.301867
112,LA_T_9540683,0,25430,0, 71/118, Time: 0.560798s, Loss: 0.301867
65,LA_T_5360018,0,54554,0, 72/118, Time: 0.560798s, Loss: 0.301867
56,LA_T_4725126,0,61141,0, 73/118, Time: 0.560798s, Loss: 0.301867
20,LA_T_2269038,0,63442,0, 74/118, Time: 0.560798s, Loss: 0.301867
74,LA_T_6301739,0,41843,0, 75/118, Time: 0.560798s, Loss: 0.301867
45,LA_T_3527643,1,8295,64000, 76/118, Time: 0.560798s, Loss: 0.301867
88,LA_T_7020532,0,59863,0, 77/118, Time: 0.560798s, Loss: 0.301867
115,LA_T_9746209,0,64000,0, 78/118, Time: 0.560798s, Loss: 0.301867
41,LA_T_3391018,0,57402,0, 79/118, Time: 0.560798s, Loss: 0.301867
60,LA_T_5205025,0,61550,0, 80/118, Time: 0.560798s, Loss: 0.301867
30,LA_T_2584761,0,47107,0, 81/118, Time: 0.560798s, Loss: 0.301867
14,LA_T_1836557,0,43646,0, 82/118, Time: 0.560798s, Loss: 0.301867
89,LA_T_7124444,0,64000,0, 83/118, Time: 0.560798s, Loss: 0.301867
99,LA_T_7529623,0,43309,0, 84/118, Time: 0.560798s, Loss: 0.301867
19,LA_T_2052267,0,38415,0, 85/118, Time: 0.560798s, Loss: 0.301867
5,LA_T_1486451,0,50406,0, 86/118, Time: 0.560798s, Loss: 0.301867
3,LA_T_1373588,0,46949,0, 87/118, Time: 0.560798s, Loss: 0.301867
98,LA_T_7422011,0,45646,0, 88/118, Time: 0.560798s, Loss: 0.301867
70,LA_T_5883755,0,64000,0, 89/118, Time: 0.560798s, Loss: 0.301867
64,LA_T_5258800,0,54370,0, 90/118, Time: 0.560798s, Loss: 0.301867
59,LA_T_5015679,0,41144,0, 91/118, Time: 0.560798s, Loss: 0.301867
107,LA_T_8206162,0,55328,0, 92/118, Time: 0.560798s, Loss: 0.301867
108,LA_T_8234484,0,46183,0, 93/118, Time: 0.560798s, Loss: 0.301867
116,LA_T_9746209,1,16967,64000, 94/118, Time: 0.560798s, Loss: 0.301867
31,LA_T_2677562,0,63649,0, 95/118, Time: 0.560798s, Loss: 0.301867
49,LA_T_3758169,0,46047,0, 96/118, Time: 0.560798s, Loss: 0.301867
78,LA_T_6435787,0,43614,0, 97/118, Time: 0.560798s, Loss: 0.301867
55,LA_T_4630359,0,64000,0, 98/118, Time: 0.560798s, Loss: 0.301867
32,LA_T_2995069,0,49112,0, 99/118, Time: 0.560798s, Loss: 0.301867
11,LA_T_1653822,0,64000,0, 100/118, Time: 0.560798s, Loss: 0.301867
95,LA_T_7314513,0,39437,0, 101/118, Time: 0.560798s, Loss: 0.301867
105,LA_T_8007992,0,45465,0, 102/118, Time: 0.560798s, Loss: 0.301867
106,LA_T_8090857,0,64000,0, 103/118, Time: 0.560798s, Loss: 0.301867
104,LA_T_7888797,0,26626,0, 104/118, Time: 0.560798s, Loss: 0.301867
24,LA_T_2327393,0,60701,0, 105/118, Time: 0.560798s, Loss: 0.301867
18,LA_T_1909651,2,24481,128000, 106/118, Time: 0.560798s, Loss: 0.301867
63,LA_T_5214047,0,41920,0, 107/118, Time: 0.560798s, Loss: 0.301867
77,LA_T_6390981,0,64000,0, 108/118, Time: 0.560798s, Loss: 0.301867
6,LA_T_1490244,0,55572,0, 109/118, Time: 0.560798s, Loss: 0.301867
35,LA_T_3176741,0,62198,0, 110/118, Time: 0.560798s, Loss: 0.301867
76,LA_T_6331069,1,64000,64000, 111/118, Time: 0.560798s, Loss: 0.301867
57,LA_T_4774044,0,59379,0, 112/118, Time: 0.560798s, Loss: 0.301867
62,LA_T_5209704,1,34511,64000, 113/118, Time: 0.560798s, Loss: 0.301867
46,LA_T_3588714,0,46298,0, 114/118, Time: 0.560798s, Loss: 0.301867
8,LA_T_1589546,0,64000,0, 115/118, Time: 0.560798s, Loss: 0.301867
113,LA_T_9633872,0,27407,0, 116/118, Time: 0.560798s, Loss: 0.301867
93,LA_T_7281115,0,64000,0, 117/118, Time: 0.560798s, Loss: 0.301867
66,LA_T_5433188,0,34172,0, 118/118, Time: 0.560798s, Loss: 0.301867
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
40,LA_D_6055606,0,53176,0, 1/63, Time: 0.263902s, Loss: 0.282054
46,LA_D_7862876,0,57311,0, 2/63, Time: 0.263902s, Loss: 0.282054
31,LA_D_5505879,0,64000,0, 3/63, Time: 0.263902s, Loss: 0.282054
43,LA_D_7026375,0,61915,0, 4/63, Time: 0.263902s, Loss: 0.282054
8,LA_D_1886178,0,40092,0, 5/63, Time: 0.263902s, Loss: 0.282054
15,LA_D_3203408,0,49607,0, 6/63, Time: 0.263902s, Loss: 0.282054
55,LA_D_9192205,0,40612,0, 7/63, Time: 0.263902s, Loss: 0.282054
42,LA_D_6502788,0,29166,0, 8/63, Time: 0.263902s, Loss: 0.282054
0,LA_D_1179848,0,64000,0, 9/63, Time: 0.263902s, Loss: 0.282054
17,LA_D_3705418,0,64000,0, 10/63, Time: 0.263902s, Loss: 0.282054
26,LA_D_5239066,0,64000,0, 11/63, Time: 0.263902s, Loss: 0.282054
27,LA_D_5239066,1,30014,64000, 12/63, Time: 0.263902s, Loss: 0.282054
25,LA_D_4630224,0,27639,0, 13/63, Time: 0.263902s, Loss: 0.282054
24,LA_D_4519635,1,12487,64000, 14/63, Time: 0.263902s, Loss: 0.282054
48,LA_D_7869978,1,20551,64000, 15/63, Time: 0.263902s, Loss: 0.282054
36,LA_D_5835948,1,29523,64000, 16/63, Time: 0.263902s, Loss: 0.282054
16,LA_D_3457616,0,51111,0, 17/63, Time: 0.263902s, Loss: 0.282054
6,LA_D_1580841,0,38838,0, 18/63, Time: 0.263902s, Loss: 0.282054
58,LA_D_9566347,0,35349,0, 19/63, Time: 0.263902s, Loss: 0.282054
37,LA_D_5891869,0,54006,0, 20/63, Time: 0.263902s, Loss: 0.282054
35,LA_D_5835948,0,64000,0, 21/63, Time: 0.263902s, Loss: 0.282054
20,LA_D_4265541,0,26061,0, 22/63, Time: 0.263902s, Loss: 0.282054
1,LA_D_1179848,1,29541,64000, 23/63, Time: 0.263902s, Loss: 0.282054
7,LA_D_1803008,0,45707,0, 24/63, Time: 0.263902s, Loss: 0.282054
18,LA_D_3983088,0,21649,0, 25/63, Time: 0.263902s, Loss: 0.282054
33,LA_D_5659407,0,64000,0, 26/63, Time: 0.263902s, Loss: 0.282054
44,LA_D_7095518,0,56482,0, 27/63, Time: 0.263902s, Loss: 0.282054
59,LA_D_9686838,0,64000,0, 28/63, Time: 0.263902s, Loss: 0.282054
11,LA_D_2648941,1,41414,64000, 29/63, Time: 0.263902s, Loss: 0.282054
29,LA_D_5300881,1,27489,64000, 30/63, Time: 0.263902s, Loss: 0.282054
50,LA_D_7974256,0,50504,0, 31/63, Time: 0.263902s, Loss: 0.282054
52,LA_D_8284460,0,50174,0, 32/63, Time: 0.263902s, Loss: 0.282054
61,LA_D_9753761,0,64000,0, 33/63, Time: 0.263902s, Loss: 0.282054
38,LA_D_5944972,0,64000,0, 34/63, Time: 0.263902s, Loss: 0.282054
5,LA_D_1435765,0,47544,0, 35/63, Time: 0.263902s, Loss: 0.282054
57,LA_D_9493396,0,40904,0, 36/63, Time: 0.263902s, Loss: 0.282054
41,LA_D_6180779,0,23109,0, 37/63, Time: 0.263902s, Loss: 0.282054
22,LA_D_4394367,0,61722,0, 38/63, Time: 0.263902s, Loss: 0.282054
14,LA_D_2949136,1,27301,64000, 39/63, Time: 0.263902s, Loss: 0.282054
45,LA_D_7452217,0,25016,0, 40/63, Time: 0.263902s, Loss: 0.282054
30,LA_D_5441528,0,24518,0, 41/63, Time: 0.263902s, Loss: 0.282054
19,LA_D_4013191,0,34443,0, 42/63, Time: 0.263902s, Loss: 0.282054
13,LA_D_2949136,0,64000,0, 43/63, Time: 0.263902s, Loss: 0.282054
2,LA_D_1317561,0,64000,0, 44/63, Time: 0.263902s, Loss: 0.282054
9,LA_D_2082512,0,53318,0, 45/63, Time: 0.263902s, Loss: 0.282054
62,LA_D_9753761,1,22997,64000, 46/63, Time: 0.263902s, Loss: 0.282054
56,LA_D_9316963,0,58699,0, 47/63, Time: 0.263902s, Loss: 0.282054
47,LA_D_7869978,0,64000,0, 48/63, Time: 0.263902s, Loss: 0.282054
12,LA_D_2896709,0,64000,0, 49/63, Time: 0.263902s, Loss: 0.282054
49,LA_D_7933136,0,64000,0, 50/63, Time: 0.263902s, Loss: 0.282054
28,LA_D_5300881,0,64000,0, 51/63, Time: 0.263902s, Loss: 0.282054
34,LA_D_5741681,0,44990,0, 52/63, Time: 0.263902s, Loss: 0.282054
51,LA_D_8228250,0,42344,0, 53/63, Time: 0.263902s, Loss: 0.282054
21,LA_D_4276413,0,49755,0, 54/63, Time: 0.263902s, Loss: 0.282054
10,LA_D_2648941,0,64000,0, 55/63, Time: 0.263902s, Loss: 0.282054
54,LA_D_8998984,0,37498,0, 56/63, Time: 0.263902s, Loss: 0.282054
53,LA_D_8584336,0,61424,0, 57/63, Time: 0.263902s, Loss: 0.282054
60,LA_D_9686838,1,28544,64000, 58/63, Time: 0.263902s, Loss: 0.282054
3,LA_D_1317561,1,8976,64000, 59/63, Time: 0.263902s, Loss: 0.282054
23,LA_D_4519635,0,64000,0, 60/63, Time: 0.263902s, Loss: 0.282054
4,LA_D_1366945,0,45986,0, 61/63, Time: 0.263902s, Loss: 0.282054
32,LA_D_5505879,1,35600,64000, 62/63, Time: 0.263902s, Loss: 0.282054
39,LA_D_5944972,1,39788,64000, 63/63, Time: 0.263902s, Loss: 0.282054
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
26,LA_T_2354581,0,47687,0, 1/118, Time: 0.515793s, Loss: 0.299437
71,LA_T_5883755,1,19926,64000, 2/118, Time: 0.515793s, Loss: 0.299437
85,LA_T_6941395,0,64000,0, 3/118, Time: 0.515793s, Loss: 0.299437
51,LA_T_3993688,0,48709,0, 4/118, Time: 0.515793s, Loss: 0.299437
77,LA_T_6390981,0,64000,0, 5/118, Time: 0.515793s, Loss: 0.299437
80,LA_T_6487227,0,44111,0, 6/118, Time: 0.515793s, Loss: 0.299437
20,LA_T_2269038,0,63442,0, 7/118, Time: 0.515793s, Loss: 0.299437
95,LA_T_7314513,0,39437,0, 8/118, Time: 0.515793s, Loss: 0.299437
41,LA_T_3391018,0,57402,0, 9/118, Time: 0.515793s, Loss: 0.299437
74,LA_T_6301739,0,41843,0, 10/118, Time: 0.515793s, Loss: 0.299437
91,LA_T_7223887,0,40210,0, 11/118, Time: 0.515793s, Loss: 0.299437
89,LA_T_7124444,0,64000,0, 12/118, Time: 0.515793s, Loss: 0.299437
62,LA_T_5209704,1,34511,64000, 13/118, Time: 0.515793s, Loss: 0.299437
9,LA_T_1589546,1,9736,64000, 14/118, Time: 0.515793s, Loss: 0.299437
19,LA_T_2052267,0,38415,0, 15/118, Time: 0.515793s, Loss: 0.299437
68,LA_T_5522733,0,61381,0, 16/118, Time: 0.515793s, Loss: 0.299437
114,LA_T_9668514,0,54564,0, 17/118, Time: 0.515793s, Loss: 0.299437
94,LA_T_7281115,1,11690,64000, 18/118, Time: 0.515793s, Loss: 0.299437
34,LA_T_3021659,1,10227,64000, 19/118, Time: 0.515793s, Loss: 0.299437
78,LA_T_6435787,0,43614,0, 20/118, Time: 0.515793s, Loss: 0.299437
101,LA_T_7706110,0,24083,0, 21/118, Time: 0.515793s, Loss: 0.299437
18,LA_T_1909651,2,24481,128000, 22/118, Time: 0.515793s, Loss: 0.299437
92,LA_T_7273305,0,53173,0, 23/118, Time: 0.515793s, Loss: 0.299437
37,LA_T_3189628,1,15851,64000, 24/118, Time: 0.515793s, Loss: 0.299437
3,LA_T_1373588,0,46949,0, 25/118, Time: 0.515793s, Loss: 0.299437
88,LA_T_7020532,0,59863,0, 26/118, Time: 0.515793s, Loss: 0.299437
28,LA_T_2419035,1,10625,64000, 27/118, Time: 0.515793s, Loss: 0.299437
110,LA_T_8681550,0,40836,0, 28/118, Time: 0.515793s, Loss: 0.299437
67,LA_T_5492534,0,28365,0, 29/118, Time: 0.515793s, Loss: 0.299437
60,LA_T_5205025,0,61550,0, 30/118, Time: 0.515793s, Loss: 0.299437
13,LA_T_1724943,0,60906,0, 31/118, Time: 0.515793s, Loss: 0.299437
43,LA_T_3467377,1,26131,64000, 32/118, Time: 0.515793s, Loss: 0.299437
96,LA_T_7359423,0,50164,0, 33/118, Time: 0.515793s, Loss: 0.299437
66,LA_T_5433188,0,34172,0, 34/118, Time: 0.515793s, Loss: 0.299437
23,LA_T_2320617,0,56846,0, 35/118, Time: 0.515793s, Loss: 0.299437
79,LA_T_6476207,0,54948,0, 36/118, Time: 0.515793s, Loss: 0.299437
116,LA_T_9746209,1,16967,64000, 37/118, Time: 0.515793s, Loss: 0.299437
54,LA_T_4584407,0,36921,0, 38/118, Time: 0.515793s, Loss: 0.299437
113,LA_T_9633872,0,27407,0, 39/118, Time: 0.515793s, Loss: 0.299437
35,LA_T_3176741,0,62198,0, 40/118, Time: 0.515793s, Loss: 0.299437
46,LA_T_3588714,0,46298,0, 41/118, Time: 0.515793s, Loss: 0.299437
59,LA_T_5015679,0,41144,0, 42/118, Time: 0.515793s, Loss: 0.299437
63,LA_T_5214047,0,41920,0, 43/118, Time: 0.515793s, Loss: 0.299437
25,LA_T_2333843,0,61708,0, 44/118, Time: 0.515793s, Loss: 0.299437
27,LA_T_2419035,0,64000,0, 45/118, Time: 0.515793s, Loss: 0.299437
99,LA_T_7529623,0,43309,0, 46/118, Time: 0.515793s, Loss: 0.299437
48,LA_T_3627265,1,44402,64000, 47/118, Time: 0.515793s, Loss: 0.299437
39,LA_T_3250806,0,61271,0, 48/118, Time: 0.515793s, Loss: 0.299437
70,LA_T_5883755,0,64000,0, 49/118, Time: 0.515793s, Loss: 0.299437
24,LA_T_2327393,0,60701,0, 50/118, Time: 0.515793s, Loss: 0.299437
56,LA_T_4725126,0,61141,0, 51/118, Time: 0.515793s, Loss: 0.299437
16,LA_T_1909651,0,64000,0, 52/118, Time: 0.515793s, Loss: 0.299437
14,LA_T_1836557,0,43646,0, 53/118, Time: 0.515793s, Loss: 0.299437
111,LA_T_9226984,0,45529,0, 54/118, Time: 0.515793s, Loss: 0.299437
44,LA_T_3527643,0,64000,0, 55/118, Time: 0.515793s, Loss: 0.299437
58,LA_T_4928920,0,64000,0, 56/118, Time: 0.515793s, Loss: 0.299437
102,LA_T_7808689,0,64000,0, 57/118, Time: 0.515793s, Loss: 0.299437
29,LA_T_2422854,0,62661,0, 58/118, Time: 0.515793s, Loss: 0.299437
11,LA_T_1653822,0,64000,0, 59/118, Time: 0.515793s, Loss: 0.299437
7,LA_T_1518499,0,29284,0, 60/118, Time: 0.515793s, Loss: 0.299437
40,LA_T_3319380,0,42032,0, 61/118, Time: 0.515793s, Loss: 0.299437
90,LA_T_7124444,1,21405,64000, 62/118, Time: 0.515793s, Loss: 0.299437
30,LA_T_2584761,0,47107,0, 63/118, Time: 0.515793s, Loss: 0.299437
73,LA_T_5978739,0,33363,0, 64/118, Time: 0.515793s, Loss: 0.299437
1,LA_T_1258641,0,44562,0, 65/118, Time: 0.559858s, Loss: 0.336203
32,LA_T_2995069,0,49112,0, 66/118, Time: 0.559858s, Loss: 0.336203
86,LA_T_6941395,1,29307,64000, 67/118, Time: 0.559858s, Loss: 0.336203
33,LA_T_3021659,0,64000,0, 68/118, Time: 0.559858s, Loss: 0.336203
2,LA_T_1346935,0,45741,0, 69/118, Time: 0.559858s, Loss: 0.336203
4,LA_T_1470918,0,39641,0, 70/118, Time: 0.559858s, Loss: 0.336203
112,LA_T_9540683,0,25430,0, 71/118, Time: 0.559858s, Loss: 0.336203
69,LA_T_5786445,0,64000,0, 72/118, Time: 0.559858s, Loss: 0.336203
83,LA_T_6751630,0,62290,0, 73/118, Time: 0.559858s, Loss: 0.336203
53,LA_T_4512109,0,51563,0, 74/118, Time: 0.559858s, Loss: 0.336203
61,LA_T_5209704,0,64000,0, 75/118, Time: 0.559858s, Loss: 0.336203
64,LA_T_5258800,0,54370,0, 76/118, Time: 0.559858s, Loss: 0.336203
0,LA_T_1154440,0,30107,0, 77/118, Time: 0.559858s, Loss: 0.336203
93,LA_T_7281115,0,64000,0, 78/118, Time: 0.559858s, Loss: 0.336203
36,LA_T_3189628,0,64000,0, 79/118, Time: 0.559858s, Loss: 0.336203
75,LA_T_6331069,0,64000,0, 80/118, Time: 0.559858s, Loss: 0.336203
104,LA_T_7888797,0,26626,0, 81/118, Time: 0.559858s, Loss: 0.336203
42,LA_T_3467377,0,64000,0, 82/118, Time: 0.559858s, Loss: 0.336203
50,LA_T_3935691,0,39156,0, 83/118, Time: 0.559858s, Loss: 0.336203
97,LA_T_7405543,0,36914,0, 84/118, Time: 0.559858s, Loss: 0.336203
8,LA_T_1589546,0,64000,0, 85/118, Time: 0.559858s, Loss: 0.336203
106,LA_T_8090857,0,64000,0, 86/118, Time: 0.559858s, Loss: 0.336203
76,LA_T_6331069,1,64000,64000, 87/118, Time: 0.559858s, Loss: 0.336203
107,LA_T_8206162,0,55328,0, 88/118, Time: 0.559858s, Loss: 0.336203
82,LA_T_6728875,0,64000,0, 89/118, Time: 0.559858s, Loss: 0.336203
52,LA_T_4096754,0,31273,0, 90/118, Time: 0.559858s, Loss: 0.336203
12,LA_T_1653822,1,9756,64000, 91/118, Time: 0.559858s, Loss: 0.336203
105,LA_T_8007992,0,45465,0, 92/118, Time: 0.559858s, Loss: 0.336203
100,LA_T_7550620,0,44981,0, 93/118, Time: 0.559858s, Loss: 0.336203
38,LA_T_3220265,0,38149,0, 94/118, Time: 0.559858s, Loss: 0.336203
47,LA_T_3627265,0,64000,0, 95/118, Time: 0.559858s, Loss: 0.336203
5,LA_T_1486451,0,50406,0, 96/118, Time: 0.559858s, Loss: 0.336203
6,LA_T_1490244,0,55572,0, 97/118, Time: 0.559858s, Loss: 0.336203
55,LA_T_4630359,0,64000,0, 98/118, Time: 0.559858s, Loss: 0.336203
10,LA_T_1630611,0,58109,0, 99/118, Time: 0.559858s, Loss: 0.336203
84,LA_T_6822716,0,27313,0, 100/118, Time: 0.559858s, Loss: 0.336203
15,LA_T_1870524,0,43190,0, 101/118, Time: 0.559858s, Loss: 0.336203
31,LA_T_2677562,0,63649,0, 102/118, Time: 0.559858s, Loss: 0.336203
17,LA_T_1909651,1,64000,64000, 103/118, Time: 0.559858s, Loss: 0.336203
72,LA_T_5894355,0,64000,0, 104/118, Time: 0.559858s, Loss: 0.336203
22,LA_T_2277153,1,21822,64000, 105/118, Time: 0.559858s, Loss: 0.336203
81,LA_T_6521388,0,64000,0, 106/118, Time: 0.559858s, Loss: 0.336203
45,LA_T_3527643,1,8295,64000, 107/118, Time: 0.559858s, Loss: 0.336203
117,LA_T_9830298,0,64000,0, 108/118, Time: 0.559858s, Loss: 0.336203
103,LA_T_7866363,0,63473,0, 109/118, Time: 0.559858s, Loss: 0.336203
49,LA_T_3758169,0,46047,0, 110/118, Time: 0.559858s, Loss: 0.336203
57,LA_T_4774044,0,59379,0, 111/118, Time: 0.559858s, Loss: 0.336203
108,LA_T_8234484,0,46183,0, 112/118, Time: 0.559858s, Loss: 0.336203
87,LA_T_6960076,0,42296,0, 113/118, Time: 0.559858s, Loss: 0.336203
65,LA_T_5360018,0,54554,0, 114/118, Time: 0.559858s, Loss: 0.336203
21,LA_T_2277153,0,64000,0, 115/118, Time: 0.559858s, Loss: 0.336203
98,LA_T_7422011,0,45646,0, 116/118, Time: 0.559858s, Loss: 0.336203
115,LA_T_9746209,0,64000,0, 117/118, Time: 0.559858s, Loss: 0.336203
109,LA_T_8527420,0,63377,0, 118/118, Time: 0.559858s, Loss: 0.336203
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
10,LA_D_2648941,0,64000,0, 1/63, Time: 0.257341s, Loss: 0.263183
24,LA_D_4519635,1,12487,64000, 2/63, Time: 0.257341s, Loss: 0.263183
7,LA_D_1803008,0,45707,0, 3/63, Time: 0.257341s, Loss: 0.263183
49,LA_D_7933136,0,64000,0, 4/63, Time: 0.257341s, Loss: 0.263183
37,LA_D_5891869,0,54006,0, 5/63, Time: 0.257341s, Loss: 0.263183
61,LA_D_9753761,0,64000,0, 6/63, Time: 0.257341s, Loss: 0.263183
26,LA_D_5239066,0,64000,0, 7/63, Time: 0.257341s, Loss: 0.263183
48,LA_D_7869978,1,20551,64000, 8/63, Time: 0.257341s, Loss: 0.263183
50,LA_D_7974256,0,50504,0, 9/63, Time: 0.257341s, Loss: 0.263183
62,LA_D_9753761,1,22997,64000, 10/63, Time: 0.257341s, Loss: 0.263183
21,LA_D_4276413,0,49755,0, 11/63, Time: 0.257341s, Loss: 0.263183
59,LA_D_9686838,0,64000,0, 12/63, Time: 0.257341s, Loss: 0.263183
8,LA_D_1886178,0,40092,0, 13/63, Time: 0.257341s, Loss: 0.263183
34,LA_D_5741681,0,44990,0, 14/63, Time: 0.257341s, Loss: 0.263183
15,LA_D_3203408,0,49607,0, 15/63, Time: 0.257341s, Loss: 0.263183
3,LA_D_1317561,1,8976,64000, 16/63, Time: 0.257341s, Loss: 0.263183
42,LA_D_6502788,0,29166,0, 17/63, Time: 0.257341s, Loss: 0.263183
28,LA_D_5300881,0,64000,0, 18/63, Time: 0.257341s, Loss: 0.263183
56,LA_D_9316963,0,58699,0, 19/63, Time: 0.257341s, Loss: 0.263183
11,LA_D_2648941,1,41414,64000, 20/63, Time: 0.257341s, Loss: 0.263183
44,LA_D_7095518,0,56482,0, 21/63, Time: 0.257341s, Loss: 0.263183
17,LA_D_3705418,0,64000,0, 22/63, Time: 0.257341s, Loss: 0.263183
36,LA_D_5835948,1,29523,64000, 23/63, Time: 0.257341s, Loss: 0.263183
53,LA_D_8584336,0,61424,0, 24/63, Time: 0.257341s, Loss: 0.263183
23,LA_D_4519635,0,64000,0, 25/63, Time: 0.257341s, Loss: 0.263183
16,LA_D_3457616,0,51111,0, 26/63, Time: 0.257341s, Loss: 0.263183
2,LA_D_1317561,0,64000,0, 27/63, Time: 0.257341s, Loss: 0.263183
41,LA_D_6180779,0,23109,0, 28/63, Time: 0.257341s, Loss: 0.263183
13,LA_D_2949136,0,64000,0, 29/63, Time: 0.257341s, Loss: 0.263183
46,LA_D_7862876,0,57311,0, 30/63, Time: 0.257341s, Loss: 0.263183
6,LA_D_1580841,0,38838,0, 31/63, Time: 0.257341s, Loss: 0.263183
30,LA_D_5441528,0,24518,0, 32/63, Time: 0.257341s, Loss: 0.263183
20,LA_D_4265541,0,26061,0, 33/63, Time: 0.257341s, Loss: 0.263183
4,LA_D_1366945,0,45986,0, 34/63, Time: 0.257341s, Loss: 0.263183
39,LA_D_5944972,1,39788,64000, 35/63, Time: 0.257341s, Loss: 0.263183
5,LA_D_1435765,0,47544,0, 36/63, Time: 0.257341s, Loss: 0.263183
33,LA_D_5659407,0,64000,0, 37/63, Time: 0.257341s, Loss: 0.263183
1,LA_D_1179848,1,29541,64000, 38/63, Time: 0.257341s, Loss: 0.263183
22,LA_D_4394367,0,61722,0, 39/63, Time: 0.257341s, Loss: 0.263183
9,LA_D_2082512,0,53318,0, 40/63, Time: 0.257341s, Loss: 0.263183
29,LA_D_5300881,1,27489,64000, 41/63, Time: 0.257341s, Loss: 0.263183
31,LA_D_5505879,0,64000,0, 42/63, Time: 0.257341s, Loss: 0.263183
25,LA_D_4630224,0,27639,0, 43/63, Time: 0.257341s, Loss: 0.263183
18,LA_D_3983088,0,21649,0, 44/63, Time: 0.257341s, Loss: 0.263183
58,LA_D_9566347,0,35349,0, 45/63, Time: 0.257341s, Loss: 0.263183
45,LA_D_7452217,0,25016,0, 46/63, Time: 0.257341s, Loss: 0.263183
38,LA_D_5944972,0,64000,0, 47/63, Time: 0.257341s, Loss: 0.263183
40,LA_D_6055606,0,53176,0, 48/63, Time: 0.257341s, Loss: 0.263183
47,LA_D_7869978,0,64000,0, 49/63, Time: 0.257341s, Loss: 0.263183
27,LA_D_5239066,1,30014,64000, 50/63, Time: 0.257341s, Loss: 0.263183
12,LA_D_2896709,0,64000,0, 51/63, Time: 0.257341s, Loss: 0.263183
54,LA_D_8998984,0,37498,0, 52/63, Time: 0.257341s, Loss: 0.263183
35,LA_D_5835948,0,64000,0, 53/63, Time: 0.257341s, Loss: 0.263183
60,LA_D_9686838,1,28544,64000, 54/63, Time: 0.257341s, Loss: 0.263183
55,LA_D_9192205,0,40612,0, 55/63, Time: 0.257341s, Loss: 0.263183
43,LA_D_7026375,0,61915,0, 56/63, Time: 0.257341s, Loss: 0.263183
51,LA_D_8228250,0,42344,0, 57/63, Time: 0.257341s, Loss: 0.263183
52,LA_D_8284460,0,50174,0, 58/63, Time: 0.257341s, Loss: 0.263183
32,LA_D_5505879,1,35600,64000, 59/63, Time: 0.257341s, Loss: 0.263183
57,LA_D_9493396,0,40904,0, 60/63, Time: 0.257341s, Loss: 0.263183
0,LA_D_1179848,0,64000,0, 61/63, Time: 0.257341s, Loss: 0.263183
14,LA_D_2949136,1,27301,64000, 62/63, Time: 0.257341s, Loss: 0.263183
19,LA_D_4013191,0,34443,0, 63/63, Time: 0.257341s, Loss: 0.263183
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Uni\FYP\Implementation\Code\SSL\core_scripts\data_io\customize_collate_fn.py:114: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = elem.storage()._new_shared(numel)
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
D:\Software\Anaconda\envs\fairseq-pip2\lib\site-packages\scipy\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
